{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2e81c6-39d5-409a-a818-978d60e63ecd",
   "metadata": {},
   "source": [
    "# Wherobots Raster Inference - Object Detection\n",
    "\n",
    "This example demonstrates an object detection model with Raster Inference to identify marine infrastructure (offshore wind farms and platforms) in satellite imagery.\n",
    "\n",
    "We will use a machine-learning model from Satlas which was trained using imagery from the European Space Agencyâ€™s Sentinel-2 satellites.\n",
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757e8aa",
   "metadata": {},
   "source": [
    "## Set up WherobotsDB context\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql.functions import expr, size, col\n",
    "from sedona.spark import *\n",
    "import json\n",
    "\n",
    "config = SedonaContext.builder().appName('object-detection-batch-inference')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654ce00-87ec-4200-88ac-feac99575490",
   "metadata": {},
   "source": [
    "## Load satellite imagery\n",
    "\n",
    "In this step, we load the satellite imagery over which we will run inference.\n",
    "These GeoTIFF images are ingested as out-of-database or **out-db** rasters in WherobotsDB and stored in the Data Hub for easy access.",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a12ce3-e74c-4f34-bd5a-aa59891c7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raster_input = sedona.table(f\"wherobots_pro_data.satlas.offshore_satlas\")\n",
    "df_raster_input.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4dce8-72d1-4710-8cb9-673a6addc60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raster_input.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf51b66-1ec0-4831-b01d-6febb5053dde",
   "metadata": {},
   "source": [
    "## Focus on a coastal region\n",
    "\n",
    "With 176,000 images covering most of Earth's coastlines, let's choose an area to focus on.\n",
    "\n",
    "You can use the interactive map below to define a Region of Interest (ROI) as a polygon using the \"Draw a Polygon\" tool in the left-hand sidebar. Or, use the default ROI (in red) that is preloaded in the map below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8f026-ddbd-46ee-a92f-071de9371691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from leafmap import Map\n",
    "\n",
    "my_map = Map(zoom=7, center = (36.5, 122))\n",
    "default_roi = {'type': 'Feature',\n",
    "                       'properties': {},\n",
    "                       'geometry': {'type': 'Polygon',\n",
    "                        'coordinates': [[[120.959473, 35.918528],\n",
    "                                        [120.959473, 36.820829],\n",
    "                                        [123.046875, 36.820829],\n",
    "                                        [123.046875, 35.918528],\n",
    "                                        [120.959473, 35.918528]]]}}\n",
    "my_map.add_geojson(default_roi, layer_name=\"Default AOI\", style={\"color\": \"#ba2762\",\"fillOpacity\": 0.5,\"fillColor\": \"#ba2762\",\"weight\": 3,})\n",
    "my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3e78c-c15a-41e8-b23a-fc08dbeb6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "if my_map.user_roi is None:\n",
    "    my_map.user_roi = default_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54154ce-2035-4799-85a1-8fc0b6e8447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_json = json.dumps(my_map.user_roi) # formats the python dictionary as a string so we can pass it to SQL\n",
    "df_raster_sub = df_raster_input.where(\n",
    "    expr(f\"\"\"ST_INTERSECTS(footprint, ST_GeomFromGeoJSON('{feature_json}'))\"\"\")\n",
    ")\n",
    "\n",
    "df_raster_sub.cache()\n",
    "print(f\"IMAGE COUNT: {df_raster_sub.count()}\")\n",
    "df_raster_sub.show(3, truncate=True)\n",
    "df_raster_sub.createOrReplaceTempView(\"df_raster_input\")\n",
    "df_raster_sub.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb48d09-cb74-40ef-a709-4850cebe1e47",
   "metadata": {},
   "source": [
    "## Viewing results\n",
    "\n",
    "With our ROI defined we can see the footprints of the images in the ROI with the `SedonaKepler.create_map()` integration. Using `SedonaUtils.display_image()` we can view the images as well.\n",
    "\n",
    "**Tip:** Save the map to a html file using `kepler_map.save_to_html()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c73c8-ff49-4b5d-9b7d-f9bbe9ad83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "\n",
    "kepler_map = SedonaKepler.create_map()\n",
    "\n",
    "SedonaKepler.add_df(kepler_map, df=df_raster_sub, name=\"Image Footprints\")\n",
    "\n",
    "kepler_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc5abd-4229-404e-97a0-a9693bd42712",
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlDf = sedona.sql(f\"\"\"SELECT RS_AsImage(outdb_raster, 250), name as FROM df_raster_input limit 5\"\"\")\n",
    "SedonaUtils.display_image(htmlDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e55013-053f-4de6-b88f-1ca0b31a0ada",
   "metadata": {},
   "source": [
    "## Run predictions and visualize results\n",
    "\n",
    "To run predictions, specify the model to use by the `model id`. Three models are pre-loaded and made available in Wherobots Cloud. You can also load your own models, learn more about that process [here](https://docs.wherobots.com/latest/tutorials/wherobotsai/wherobots-inference/raster-inference-overview/?h=bring#bring-your-own-model-guide).\n",
    "\n",
    "Inference can be run using **Wherobots' Spatial SQL functions**, in this case: `RS_DETECT_BBOXES()`.\n",
    "\n",
    "Here we generate predictions for all images in the ROI. The predictions output has two labels, `1` for offshore wind turbines and `2` for offshore platfroms. \n",
    "\n",
    "Then filter and print some of the results to see how non-detect and positive detect results look. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f647116-0022-4234-b5ef-64c09fcf20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'marine-satlas-sentinel2'\n",
    "\n",
    "predictions_df = sedona.sql(f\"\"\"\n",
    "SELECT\n",
    "  outdb_raster,\n",
    "  name as image_name,\n",
    "  detect_result.*\n",
    "FROM (\n",
    "  SELECT\n",
    "    outdb_raster,\n",
    "    name,\n",
    "    RS_DETECT_BBOXES('{model_id}', outdb_raster) AS detect_result\n",
    "  FROM\n",
    "    df_raster_input\n",
    ") AS detect_fields\n",
    "\"\"\")\n",
    "\n",
    "predictions_df.cache().count()\n",
    "predictions_df.filter(size(col(\"labels\")) == 0).show(3)\n",
    "predictions_df.filter(size(col(\"labels\")) == 1).show(3)\n",
    "predictions_df.createOrReplaceTempView(\"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666348a-ca17-47a5-a4f8-c94068f49c9c",
   "metadata": {},
   "source": [
    "## Run predictions and visualize results\n",
    "\n",
    "Since we ran inference across a lot of coastline, many scenes don't contain wind farms and don't have positive detections. Now that we've generated predictions using our model over our satellite imagery, we can filter the geometries by confidence score with `RS_FILTER_BOX_CONFIDENCE` and by the integer label representing offshore wind farms, `1`, to locate predicted offshore wind farms (label `2` is the integer label representing offshore platforms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e8c42-82a6-42aa-9418-c317094bfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_predictions = sedona.sql(f\"\"\"\n",
    "  SELECT\n",
    "    outdb_raster,\n",
    "    image_name,\n",
    "    filtered.*\n",
    "  FROM (\n",
    "    SELECT\n",
    "      outdb_raster,\n",
    "      image_name,\n",
    "      RS_FILTER_BOX_CONFIDENCE(bboxes_wkt, confidence_scores, labels, 0.65) AS filtered\n",
    "    FROM\n",
    "      predictions\n",
    "  ) AS temp\n",
    "    WHERE size(filtered.max_confidence_bboxes) > 0\n",
    "    AND \n",
    "        array_contains(filtered.max_confidence_labels, '1')\n",
    "\"\"\")\n",
    "filtered_predictions.createOrReplaceTempView(\"filtered_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcfbb2-e762-4976-830d-9a63daccccde",
   "metadata": {},
   "source": [
    "## Prepare results\n",
    "\n",
    "Before plotting our predictions we need to transfrom our results. \n",
    "\n",
    "We need our table in a structure where each row represents _all_ of a raster scene's bounding box predictions to a format where each row represents a _single_ predicted bounding box. \n",
    "\n",
    "To do this, combine the list columns containing our prediction results (`max_confidence_bboxes`, `max_confidence_scores`, and `max_confidence_labels`) with `arrays_zip`.  Then use `explode` to convert lists to rows. \n",
    "\n",
    "To map the results with `SedonaKepler`, convert the `max_confidence_bboxes` column to a `GeometryType` column with `ST_GeomFromWKT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105badd3-dd9e-4a2e-85ab-72bbfe6bdb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = sedona.sql(\"\"\"\n",
    "SELECT\n",
    "    outdb_raster,\n",
    "    image_name,\n",
    "    exploded.*\n",
    "FROM (\n",
    "    SELECT\n",
    "        outdb_raster,\n",
    "        image_name,\n",
    "        explode(arrays_zip(max_confidence_bboxes, max_confidence_scores, max_confidence_labels)) AS exploded\n",
    "    FROM\n",
    "        filtered_predictions\n",
    ") temp\n",
    "\"\"\")\n",
    "df_exploded = exploded_df.withColumn(\"geometry\", expr(\"ST_GeomFromWkt(max_confidence_bboxes)\")).drop(\"max_confidence_bboxes\")\n",
    "print(df_exploded.cache().count())\n",
    "df_exploded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca987b-7bf7-40e8-98bb-7baee0171ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "\n",
    "kepler_map = SedonaKepler.create_map()\n",
    "\n",
    "SedonaKepler.add_df(kepler_map, df=df_exploded.drop(\"outdb_raster\"), name=\"Wind Farm Detections\")\n",
    "kepler_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ff035-32bb-443b-9f0b-9f5bccbc06b1",
   "metadata": {},
   "source": [
    "## Select a footprint and review the image\n",
    "\n",
    "Select one of the detected footprints from the map above. Copy the name of a detected bounding box and paste it into the query below to retrieve the corresponding image.\n",
    "\n",
    ">**Remember:** If you changed the ROI at the begining the `image_name` below might not be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67b12d-eeaf-4300-869c-35e94fc6d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = '2015411785-5-6.tiff'\n",
    "htmlDf = sedona.sql(f\"\"\"SELECT RS_AsImage(outdb_raster, 500), name FROM df_raster_input WHERE name = '{image_name}' \"\"\")\n",
    "SedonaUtils.display_image(htmlDf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2952aaa1-9479-4bc5-98bc-461bc604bf48",
   "metadata": {},
   "source": [
    "## Python API for wherobots.inference\n",
    "\n",
    "If you prefer python, wherobots.inference offers a module for registering the SQL inference functions as python functions. Below we run the same inference as before with `RS_DETECT_BBOXES`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e631a91-6837-4bfe-a50f-6968eaac6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wherobots.inference.engine.register import create_object_detection_udfs\n",
    "from pyspark.sql.functions import col\n",
    "rs_detect, rs_threshold_geoms, rs_text_to_bboxes =  create_object_detection_udfs(batch_size = 10, sedona=sedona)\n",
    "df = df_raster_input.withColumn(\"detect_result\", rs_detect(model_id, col(\"outdb_raster\"))).select(\n",
    "                               \"outdb_raster\",\n",
    "                               col(\"detect_result.bboxes_wkt\").alias(\"bboxes_wkt\"),\n",
    "                               col(\"detect_result.confidence_scores\").alias(\"confidence_scores\"),\n",
    "                               col(\"detect_result.labels\").alias(\"labels\")\n",
    "                           )\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
