{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring Your Own Rasters (BYOR) with RasterFlow\n",
    "\n",
    "This notebook demonstrates how to bring your own rasters (BYOR) into RasterFlow by querying a STAC catalog and creating a GTI (GDAL Raster Tile Index). You will learn how to query the NAIP collection, extract Cloud-Optimized GeoTIFF (COG) URLs, and build a mosaic using RasterFlow's `build_gti_mosaic` function.\n",
    "\n",
    "## What you will learn\n",
    "\n",
    "This notebook will teach you to:\n",
    "\n",
    "- Query a STAC catalog to discover available imagery for an area of interest\n",
    "- Create a GTI (GDAL Raster Tile Index) from STAC items\n",
    "- Build a seamless mosaic from multiple image tiles using RasterFlow's `build_gti_mosaic`\n",
    "- Visualize the resulting mosaic using xarray and hvplot\n",
    "- (Optional) Run road detection using the ChesapeakeRSC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIP (National Agriculture Imagery Program)\n",
    "\n",
    "The [National Agriculture Imagery Program (NAIP)](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-aerial-photography-national-agriculture-imagery-program-naip) acquires aerial imagery during the agricultural growing seasons in the continental United States.\n",
    "\n",
    "Key characteristics:\n",
    "- **Resolution**: 1 meter ground sample distance\n",
    "- **Bands**: 4-band imagery (Red, Green, Blue, NIR) in a single COG file\n",
    "- **Coverage**: Continental United States\n",
    "- **Update cycle**: Typically every 2-3 years per state\n",
    "\n",
    "We will use the Element84 Earth Search STAC catalog to query NAIP imagery for Montgomery County, Maryland."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import wkls\n",
    "from leafmap import Map\n",
    "from pyspark.sql import functions as F\n",
    "from sedona.spark import *\n",
    "\n",
    "config = SedonaContext.builder().getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting an Area of Interest (AOI)\n",
    "\n",
    "We will use Montgomery County, Maryland as our AOI. This county is well-covered by NAIP imagery and provides a good example for demonstrating the BYOI workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a geometry for Montgomery County, MD using Well-Known Locations (https://github.com/wherobots/wkls)\n",
    "gdf = gpd.read_file(wkls['us']['md']['montgomery county'].geojson())\n",
    "\n",
    "# Save the geometry to a parquet file in the user's S3 path\n",
    "aoi_path = os.getenv(\"USER_S3_PATH\") + \"montgomery_county_md.parquet\"\n",
    "gdf.to_parquet(aoi_path)\n",
    "\n",
    "print(f\"AOI saved to: {aoi_path}\")\n",
    "print(f\"Bounding box: {gdf.total_bounds}\")\n",
    "print(f\"CRS: {gdf.crs}\")\n",
    "\n",
    "# Display the AOI boundary on an interactive map with basemap\n",
    "minx, miny, maxx, maxy = gdf.total_bounds\n",
    "center_lat = (miny + maxy) / 2\n",
    "center_lon = (minx + maxx) / 2\n",
    "\n",
    "m = Map(center=(center_lat, center_lon), zoom=10)\n",
    "m.add_gdf(\n",
    "    gdf, \n",
    "    layer_name=\"Montgomery County, MD\", \n",
    "    zoom_to_layer=True,\n",
    "    style={\"color\": \"red\", \"fillColor\": \"lightblue\", \"fillOpacity\": 0.3, \"weight\": 2}\n",
    ")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the NAIP STAC collection\n",
    "\n",
    "We use Wherobots' built-in STAC reader to load the NAIP collection from Element84's Earth Search catalog. This catalog provides direct S3 URLs to the imagery files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual polygon geometry as WKT for spatial filter\n",
    "aoi_wkt = gdf.geometry.iloc[0].wkt\n",
    "\n",
    "print(f\"AOI geometry type: {gdf.geometry.iloc[0].geom_type}\")\n",
    "print(f\"AOI WKT (first 200 chars): {aoi_wkt[:200]}...\")\n",
    "\n",
    "# Load NAIP collection from Element84 Earth Search\n",
    "# This catalog provides S3 URLs directly (no URL conversion needed)\n",
    "naip_df = (\n",
    "    sedona.read.format(\"stac\")\n",
    "    .option(\"itemsLimitMax\", \"200\")\n",
    "    .option(\"itemsLimitPerRequest\", \"50\")\n",
    "    .load(\"https://earth-search.aws.element84.com/v1/collections/naip\")\n",
    ")\n",
    "\n",
    "naip_df.createOrReplaceTempView(\"naip_raw\")\n",
    "\n",
    "print(f\"\\nLoaded NAIP STAC collection\")\n",
    "print(f\"Schema:\")\n",
    "naip_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying spatial and temporal filters\n",
    "\n",
    "We filter the NAIP collection to only include tiles that:\n",
    "- Intersect with our AOI (Montgomery County)\n",
    "- Were captured in 2017 (the most recent year with 1-meter resolution NAIP imagery available for Maryland so we can test the ChespeakeRSC model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by:\n",
    "# - Date range: 2017 (full year)\n",
    "# - Spatial: Intersects with Montgomery County polygon boundary\n",
    "\n",
    "filtered_df = sedona.sql(f\"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        geometry,\n",
    "        datetime,\n",
    "        assets\n",
    "    FROM naip_raw\n",
    "    WHERE datetime BETWEEN '2017-01-01' AND '2017-12-31'\n",
    "      AND ST_Intersects(geometry, ST_GeomFromText('{aoi_wkt}'))\n",
    "\"\"\")\n",
    "\n",
    "filtered_df.createOrReplaceTempView(\"naip_filtered\")\n",
    "\n",
    "tile_count = filtered_df.count()\n",
    "print(f\"Found {tile_count} NAIP tiles for Montgomery County, MD in 2017\")\n",
    "filtered_df.select(\"id\", \"datetime\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the STAC asset structure\n",
    "\n",
    "Before creating the GTI, we need to understand the structure of the STAC assets. NAIP stores all 4 bands (RGBIR) in a single COG file, so we only need one row per tile in our GTI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the assets structure\n",
    "# NAIP has a single 'image' asset containing all 4 bands (RGBIR)\n",
    "\n",
    "sample_df = sedona.sql(\"SELECT id, assets FROM naip_filtered LIMIT 1\")\n",
    "sample = sample_df.first()\n",
    "\n",
    "if sample:\n",
    "    print(f\"Tile ID: {sample['id']}\")\n",
    "    print(f\"\\nAvailable asset keys:\")\n",
    "    for key in sorted(sample['assets'].keys()):\n",
    "        print(f\"  - {key}\")\n",
    "    \n",
    "    # Check structure of the 'image' asset (4-band COG)\n",
    "    print(f\"\\n--- Structure of 'image' asset ---\")\n",
    "    image_asset = sample['assets'].get('image')\n",
    "    if image_asset:\n",
    "        print(f\"Type: {type(image_asset)}\")\n",
    "        print(f\"Content: {image_asset}\")\n",
    "else:\n",
    "    print(\"No samples found - check filters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the S3 URL for the 4-band COG\n",
    "# NAIP URLs are already in S3 format (no conversion needed!)\n",
    "\n",
    "sample_df = sedona.sql(\"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        assets['image'].href as image_url\n",
    "    FROM naip_filtered \n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "sample_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the GTI (GDAL Raster Tile Index)\n",
    "\n",
    "The GTI is a spatial index that maps tile geometries to their corresponding COG URLs.  For more information on GTI, see [the reference documentation](https://gdal.org/en/stable/drivers/raster/gti.html).\n",
    "\n",
    "Since NAIP has a single 4-band COG per tile, we create one row per tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GTI\n",
    "# NAIP has a single 4-band COG per tile, so we just need one row per tile\n",
    "\n",
    "gti_df = sedona.sql(\"\"\"\n",
    "    SELECT \n",
    "        id as tile_id,\n",
    "        ST_AsText(geometry) as geometry_wkt,\n",
    "        geometry,\n",
    "        datetime,\n",
    "        assets['image'].href as url\n",
    "    FROM naip_filtered\n",
    "    WHERE assets['image'] IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Filter out any rows where URL is null\n",
    "gti_df = gti_df.filter(F.col(\"url\").isNotNull())\n",
    "\n",
    "gti_df.createOrReplaceTempView(\"gti\")\n",
    "\n",
    "row_count = gti_df.count()\n",
    "print(f\"GTI has {row_count} rows (one row per NAIP tile)\")\n",
    "gti_df.select(\"tile_id\", \"datetime\", \"url\").show(10, truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the GTI as GeoParquet\n",
    "\n",
    "We convert the Spark DataFrame to a GeoDataFrame and save it as GeoParquet for use with RasterFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "# Select columns for the GTI (excluding the Sedona geometry, using WKT instead)\n",
    "gti_export_df = gti_df.select(\n",
    "    \"tile_id\",\n",
    "    \"geometry_wkt\",\n",
    "    \"datetime\",\n",
    "    \"url\"\n",
    ")\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "gti_pandas = gti_export_df.toPandas()\n",
    "\n",
    "# Convert WKT geometry to Shapely geometry and create GeoDataFrame\n",
    "gti_pandas['geometry'] = gti_pandas['geometry_wkt'].apply(wkt.loads)\n",
    "gti_gdf = gpd.GeoDataFrame(gti_pandas, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Drop the WKT column (no longer needed)\n",
    "gti_gdf = gti_gdf.drop(columns=['geometry_wkt'])\n",
    "\n",
    "# Save to S3 as GeoParquet\n",
    "gti_path = os.getenv(\"USER_S3_PATH\") + \"naip_gti.parquet\"\n",
    "gti_gdf.to_parquet(gti_path)\n",
    "\n",
    "print(f\"GTI saved to: {gti_path}\")\n",
    "print(f\"\\nGTI Schema:\")\n",
    "print(gti_gdf.dtypes)\n",
    "print(f\"\\nSample rows:\")\n",
    "gti_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying the GTI\n",
    "\n",
    "Before building the mosaic, we verify that the GTI was saved correctly and visualize the tile footprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload and verify the GTI\n",
    "gti_verify = gpd.read_parquet(gti_path)\n",
    "\n",
    "print(f\"GTI contains {len(gti_verify)} rows\")\n",
    "print(f\"Unique tiles: {gti_verify['tile_id'].nunique()}\")\n",
    "print(f\"Date range: {gti_verify['datetime'].min()} to {gti_verify['datetime'].max()}\")\n",
    "\n",
    "print(f\"\\nSample URLs:\")\n",
    "for i, row in gti_verify.head(3).iterrows():\n",
    "    print(f\"  {row['tile_id']}: {row['url'][:70]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the GTI footprints with the AOI boundary on an interactive map\n",
    "\n",
    "# Calculate center from the AOI\n",
    "minx, miny, maxx, maxy = gdf.total_bounds\n",
    "center_lat = (miny + maxy) / 2\n",
    "center_lon = (minx + maxx) / 2\n",
    "\n",
    "m = Map(center=(center_lat, center_lon), zoom=10)\n",
    "\n",
    "# Add NAIP tile footprints\n",
    "m.add_gdf(\n",
    "    gti_verify, \n",
    "    layer_name=\"NAIP Tile Footprints\", \n",
    "    style={\"color\": \"blue\", \"fillColor\": \"lightblue\", \"fillOpacity\": 0.3, \"weight\": 1}\n",
    ")\n",
    "\n",
    "# Add AOI boundary on top\n",
    "m.add_gdf(\n",
    "    gdf, \n",
    "    layer_name=\"Montgomery County, MD\", \n",
    "    zoom_to_layer=True,\n",
    "    style={\"color\": \"red\", \"fillColor\": \"none\", \"fillOpacity\": 0, \"weight\": 3}\n",
    ")\n",
    "\n",
    "print(f\"Showing {len(gti_verify)} NAIP tile footprints over Montgomery County, MD\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a mosaic with RasterFlow\n",
    "\n",
    "Now we use RasterFlow's `build_gti_mosaic` function to create a seamless 4-band mosaic from the NAIP tiles.\n",
    "\n",
    "> **Note:** The `naip-analytic` S3 bucket is requester-pays, so we set `requester_pays=True`.\n",
    "\n",
    "**Expected runtime: ~5-10 minutes** depending on the number of tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterflow_remote import RasterflowClient\n",
    "\n",
    "client = RasterflowClient()\n",
    "\n",
    "# Build a 4-band mosaic (Red, Green, Blue, NIR)\n",
    "store = client.build_gti_mosaic(\n",
    "    # Path to the GTI GeoParquet file\n",
    "    gti=os.getenv(\"USER_S3_PATH\") + \"naip_gti.parquet\",\n",
    "    \n",
    "    # Path to the AOI GeoParquet file\n",
    "    aoi=os.getenv(\"USER_S3_PATH\") + \"montgomery_county_md.parquet\",\n",
    "    \n",
    "    # Output bands (NAIP has 4 bands: r, g, b, ir)\n",
    "    # Note: We use 'ir' to match the ChesapeakeRSC model's expected input bands\n",
    "    bands=[\"r\", \"g\", \"b\", \"ir\"],\n",
    "    \n",
    "    # Column in the GTI containing the COG URLs\n",
    "    location_field=\"url\",\n",
    "    \n",
    "    # Output CRS (UTM Zone 18N covers Maryland)\n",
    "    crs_epsg=32618,\n",
    "    \n",
    "    # NAIP bucket is requester-pays\n",
    "    requester_pays=True,\n",
    "    \n",
    "    # NAIP uses 0 as nodata value\n",
    "    nodata=0.0,\n",
    ")\n",
    "\n",
    "print(f\"Mosaic store: {store}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the mosaic\n",
    "\n",
    "We load the Zarr store and visualize a small RGB subset of the mosaic.\n",
    "\n",
    "> **Note:** We visualize a ~2km x 2km preview area near the center of the AOI. Rendering the full county at 1-meter resolution would be too large for efficient display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import zarr\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Open the Zarr store\n",
    "fs = s3fs.S3FileSystem(profile=\"default\", asynchronous=True)\n",
    "zstore = zarr.storage.FsspecStore(fs, path=store[5:])\n",
    "ds = xr.open_zarr(zstore)\n",
    "\n",
    "# Create a transformer to convert from lat/lon to the mosaic CRS (UTM 18N)\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32618\", always_xy=True)\n",
    "\n",
    "# Define a small preview area (~2km x 2km) near the center of the AOI\n",
    "# Using the full AOI at 1m resolution would be too large to render efficiently\n",
    "preview_center_lon = (minx + maxx) / 2\n",
    "preview_center_lat = (miny + maxy) / 2\n",
    "preview_size = 0.01  # ~1km in each direction (total ~2km x 2km)\n",
    "\n",
    "preview_min_lon = preview_center_lon - preview_size\n",
    "preview_max_lon = preview_center_lon + preview_size\n",
    "preview_min_lat = preview_center_lat - preview_size\n",
    "preview_max_lat = preview_center_lat + preview_size\n",
    "\n",
    "# Transform preview bounding box coordinates from lat/lon to UTM meters\n",
    "(min_x, max_x), (min_y, max_y) = transformer.transform(\n",
    "    [preview_min_lon, preview_max_lon],\n",
    "    [preview_min_lat, preview_max_lat]\n",
    ")\n",
    "\n",
    "# Slice the dataset to the preview bounding box\n",
    "# y=slice(max_y, min_y) handles the standard \"North-to-South\" image orientation\n",
    "ds_subset = ds.sel(\n",
    "    x=slice(min_x, max_x),\n",
    "    y=slice(max_y, min_y)\n",
    ")\n",
    "\n",
    "# Select RGB bands and create array for visualization\n",
    "# NAIP bands are named: r, g, b, ir\n",
    "rgb = ds_subset.sel(band=[\"r\", \"g\", \"b\"])[\"variables\"]\n",
    "\n",
    "# Handle time dimension if present\n",
    "if \"time\" in rgb.dims:\n",
    "    rgb = rgb.isel(time=0)\n",
    "\n",
    "# Normalize values for display (NAIP values typically 0-255)\n",
    "rgb_normalized = rgb / 255.0\n",
    "rgb_normalized = rgb_normalized.clip(0, 1)\n",
    "\n",
    "# Visualize as RGB composite\n",
    "rgb_normalized.hvplot.rgb(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    bands=\"band\",\n",
    "    data_aspect=1,\n",
    "    xaxis=False,\n",
    "    yaxis=False,\n",
    "    title=\"NAIP Mosaic (RGB) - Preview\",\n",
    "    frame_width=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Running inference with ChesapeakeRSC\n",
    "\n",
    "Now that we have built the NAIP mosaic, we can optionally run a semantic segmentation model to detect roads. The [ChesapeakeRSC](https://github.com/isaaccorley/ChesapeakeRSC) model was trained on NAIP imagery from Maryland and can detect roads even when occluded by tree cover.\n",
    "\n",
    "The model outputs two classes:\n",
    "- `background`\n",
    "- `road`\n",
    "\n",
    "**Expected runtime: ~10-20 minutes** depending on the mosaic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to run road detection on the NAIP mosaic\n",
    "# \n",
    "# from rasterflow_remote import InferenceActorEnum\n",
    "# from rasterflow_remote.data_models import MergeModeEnum\n",
    "# \n",
    "# # ChesapeakeRSC model - direct URL (no HuggingFace auth required)\n",
    "# MODEL_PATH = \"https://huggingface.co/wherobots/chesapeakersc-pt2/resolve/main/chesapeakersc-ep.pt2\"\n",
    "# \n",
    "# prediction_store = client.predict_mosaic(\n",
    "#     store=store,\n",
    "#     model_path=MODEL_PATH,\n",
    "#     patch_size=512,\n",
    "#     clip_size=64,\n",
    "#     device=\"cuda\",\n",
    "#     features=[\"r\", \"g\", \"b\", \"ir\"],  # Must match the bands in our mosaic\n",
    "#     labels=[\"background\", \"road\"],\n",
    "#     actor=InferenceActorEnum.SEMANTIC_SEGMENTATION_PYTORCH,\n",
    "#     max_batch_size=256,\n",
    "#     merge_mode=MergeModeEnum.WEIGHTED_AVERAGE,\n",
    "# )\n",
    "# \n",
    "# print(f\"Prediction store: {prediction_store}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Visualizing the road detection results\n",
    "\n",
    "We can visualize the road detection output by loading the prediction Zarr store and displaying the `road` class probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to visualize road detection results\n",
    "# \n",
    "# # Open the prediction Zarr store\n",
    "# pred_zstore = zarr.storage.FsspecStore(fs, path=prediction_store[5:])\n",
    "# pred_ds = xr.open_zarr(pred_zstore)\n",
    "# \n",
    "# # Slice to the same preview area as the RGB visualization\n",
    "# pred_subset = pred_ds.sel(\n",
    "#     x=slice(min_x, max_x),\n",
    "#     y=slice(max_y, min_y)\n",
    "# )\n",
    "# \n",
    "# # Select the 'road' band\n",
    "# road_probs = pred_subset.sel(band=\"road\")[\"variables\"]\n",
    "# \n",
    "# # Handle time dimension if present\n",
    "# if \"time\" in road_probs.dims:\n",
    "#     road_probs = road_probs.isel(time=0)\n",
    "# \n",
    "# # Visualize road probability\n",
    "# road_probs.hvplot(\n",
    "#     x=\"x\",\n",
    "#     y=\"y\",\n",
    "#     cmap=\"Reds\",\n",
    "#     data_aspect=1,\n",
    "#     xaxis=False,\n",
    "#     yaxis=False,\n",
    "#     title=\"ChesapeakeRSC Road Detection - Preview\",\n",
    "#     frame_width=600,\n",
    "#     clabel=\"Road Probability\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
