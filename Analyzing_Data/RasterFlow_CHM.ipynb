{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa47acec",
   "metadata": {},
   "source": [
    "<img src=\"assets/img/chm-banner.jpg\">\n",
    "\n",
    "# Estimating canopy height with RasterFlow\n",
    "\n",
    "This notebook will guide you through estimating canopy height from aerial imagery, using Wherobots RasterFlow and the [Meta and World Resources Institute's Canopy Height prediction model (Meta CHM v1)](https://github.com/facebookresearch/HighResCanopyHeight/)<sup>1</sup>. This is an open source regression model that can predict the height of the tree canopy from high resolution imagery. The result of the model is a raster where each pixel is the estimated tree canopy height in meters.\n",
    "\n",
    "It was trained on high-resoluton imagery ([Maxar Vivid2 mosaic](https://pro-docs.maxar.com/en-us/VividMosaics/VividMosaics_intro.htm) with 0.5m resolution), existing labeled canopy height maps and airborne laser scans (LIDAR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a9b70-8490-4193-87de-75232a26892a",
   "metadata": {},
   "source": [
    "## Running inference on high resolution imagery\n",
    "\n",
    "The Meta CHM v1 model was trained on 50cm resolution data, so we will select imagery with a similar resolution for our testing.\n",
    "\n",
    "The National Agriculture Imagery Program (NAIP) provides aerial imagery for the United States, capturing high-resolution images during the agricultural growing seasons. The NAIP dataset contains a mixture of resolutions (30cm, 60cm and 1m).  See [this map](https://esri.maps.arcgis.com/apps/mapviewer/index.html?webmap=6cc0dcb225de4cb8aaa23c6a9cb59db8) for more details.  We will use 60cm imagery to test this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a65529",
   "metadata": {},
   "source": [
    "## Selecting an Area of Interest (AOI)\n",
    "We will choose an Area of Interest (AOI) for our analysis. \n",
    "\n",
    "The area around Nashua, NH has a combination of urban settings, parks and forests so we will try out the model there.  From the map, we see that 60cm imagery for New Hampshire was last captured in 2021, so we will set our time range accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c7f20d-bf38-472a-9aaf-83218a4c8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wkls\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "# Generate a geometry for Nashua, NH using WKLS (https://github.com/wherobots/wkls)\n",
    "gdf = gpd.read_file(wkls.us.nh.nashua.geojson())\n",
    "\n",
    "# Save the geometry to a parquet file in the user's S3 path\n",
    "aoi_path = os.getenv(\"USER_S3_PATH\") + \"nashua.parquet\"\n",
    "gdf.to_parquet(aoi_path)\n",
    "\n",
    "# we'll make variables for the bounds of our aoi for use after running inference to visualize results\n",
    "min_lon, min_lat, max_lon, max_lat = gdf.total_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2b94c",
   "metadata": {},
   "source": [
    "## Initializing the RasterFlow client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4534b-5ca6-448f-8215-c4a97c410452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from rasterflow_remote import RasterflowClient\n",
    "\n",
    "from rasterflow_remote.data_models import (\n",
    "    ModelRecipes\n",
    ")\n",
    "\n",
    "rf_client = RasterflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e414dee",
   "metadata": {},
   "source": [
    "## Running a model\n",
    "\n",
    "RasterFlow has pre-defined workflows to simplify orchestration of the processing steps for model inference.  These steps include:\n",
    "* Ingesting imagery for the specified Area of Interest (AOI)\n",
    "* Generating a seamless image from multiple image tiles (a mosaic) \n",
    "* Running inference with the selected model\n",
    "\n",
    "The output is a Zarr store of the model outputs.\n",
    "\n",
    "Note: This step will take approximately 20 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = rf_client.build_and_predict_mosaic_recipe(\n",
    "    # Path to our AOI in GeoParquet or GeoJSON format\n",
    "    aoi = aoi_path,\n",
    "\n",
    "    # Date range for imagery to be used by the model\n",
    "    start = datetime(2021, 1, 1),\n",
    "    end = datetime(2022, 1, 1),\n",
    "\n",
    "    # Coordinate Reference System EPSG code for the output mosaic   \n",
    "    crs_epsg = 3857,\n",
    "\n",
    "    # The model recipe to be used for inference (CHM in this case)\n",
    "    model_recipe = ModelRecipes.META_CHM_V1\n",
    ")\n",
    "\n",
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6fc2ab",
   "metadata": {},
   "source": [
    "## Visualize a subset of the model outputs\n",
    "We will use hvplot and datashader to visualize a small subset of the model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1778a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for visualization and coordinate transformation\n",
    "import hvplot.xarray\n",
    "import xarray as xr\n",
    "import s3fs \n",
    "import zarr\n",
    "from pyproj import Transformer\n",
    "from holoviews.element.tiles import EsriImagery \n",
    "\n",
    "# Open the Zarr store\n",
    "fs = s3fs.S3FileSystem(profile=\"default\", asynchronous=True)\n",
    "zstore = zarr.storage.FsspecStore(fs, path=model_outputs[5:])\n",
    "ds = xr.open_zarr(zstore)\n",
    "\n",
    "# Create a transformer to convert from lat/lon to meters\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True)\n",
    "\n",
    "# Transform boudning box coordinates from lat/lon to meters\n",
    "(min_x, max_x), (min_y, max_y) = transformer.transform(\n",
    "    [min_lon, max_lon], \n",
    "    [min_lat, max_lat]\n",
    ")\n",
    "\n",
    "# Select the height variable and slice the dataset to the bounding box\n",
    "# y=slice(max_y, min_y) handles the standard \"North-to-South\" image orientation\n",
    "ds_subset = ds.sel(band=\"height\",\n",
    "    x=slice(min_x, max_x), \n",
    "    y=slice(max_y, min_y) \n",
    ")\n",
    "\n",
    "# Select the first time step and extract the variables array\n",
    "arr_subset = ds_subset.isel(time=0)[\"variables\"]\n",
    "\n",
    "# Create a base map layer using Esri satellite imagery\n",
    "base_map = EsriImagery()\n",
    "\n",
    "# Create an overlay layer from the model outputs with hvplot\n",
    "output_layer = arr_subset.hvplot(\n",
    "    x = \"x\",\n",
    "    y = \"y\",\n",
    "    geo = True,           # Enable geographic plotting\n",
    "    dynamic = True,       # Enable dynamic rendering for interactivity\n",
    "    rasterize = True,     # Use datashader for efficient rendering of large datasets\n",
    "    cmap = \"viridis\",     # Color map for visualization\n",
    "    aspect = \"equal\",     # Maintain equal aspect ratio\n",
    "    title = \"CHM Model Outputs\" \n",
    ").opts(\n",
    "    width = 600, \n",
    "    height = 600,\n",
    "    alpha = 0.7           # Set transparency to see the base map underneath\n",
    ")\n",
    "\n",
    "# Combine the base map and output layer\n",
    "final_plot = base_map * output_layer\n",
    "final_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e79110",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. **Tolan, J., Yang, H.-I., Nosarzewski, B., Couairon, G., Vo, H. V., Brandt, J., Spore, J., Majumdar, S., Haziza, D., Vamaraju, J., et al. (2024).** Very high resolution canopy height maps from RGB imagery using self-supervised vision transformer and convolutional decoder trained on aerial lidar. *Remote Sensing of Environment*, 300, 113888."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
