{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa47acec",
   "metadata": {},
   "source": [
    "<img src=\"assets/img/ftw-banner.jpg\">\n",
    "\n",
    "# Detecting field boundaries with RasterFlow\n",
    "\n",
    "This notebook will guide you through detecting field boundaries from satellite imagery, using Wherobots RasterFlow and the Fields of the World model. You will gain a hands-on understanding of how to run models like Fields of the World on your selected area of interest, vectorize the model outputs, and work with those vectors in WherobotsDB.\n",
    "\n",
    "## What you will learn\n",
    "\n",
    "This notebook will teach you to:\n",
    "\n",
    "* Use RasterFlow to run GeoAI models like Fields of the World and generate inference results, like detected field boundaries \n",
    "* Vectorize those model outputs into geometries that can be further processed in WherobotsDB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76561f61",
   "metadata": {},
   "source": [
    "### Fields of the World (FTW)\n",
    "\n",
    "The [Fields of the World (FTW)](https://fieldsofthe.world/)<sup>1</sup> model is an example of an open segmentation model that can segment crop field boundaries from open satellite imagery (Sentinel-2).\n",
    "\n",
    "This model predicts 3 classes:\n",
    "- non_field_background\n",
    "- field\n",
    "- field_boundaries  \n",
    "\n",
    "It was trained on Sentinel-2 satellite imagery and labeled data crop field data from 24 countries across 4 continents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a65529",
   "metadata": {},
   "source": [
    "## Selecting an Area of Interest (AOI)\n",
    "We will choose an Area of Interest (AOI) for our analysis. The area around Haskell County, Kansas has some interesting crop field patterns so we will try out the model there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7139d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wkls\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "# Generate a geometry for Haskell County, Kansas using WKLS (https://github.com/wherobots/wkls)\n",
    "gdf = gpd.read_file(wkls['us']['ks']['Haskell County'].geojson())\n",
    "\n",
    "# Save the geometry to a parquet file in the user's S3 path\n",
    "aoi_path = os.getenv(\"USER_S3_PATH\") + \"haskell.parquet\"\n",
    "gdf.to_parquet(aoi_path)\n",
    "\n",
    "# Make variables for the bounds of our aoi for visualizing results after inference\n",
    "min_lon, min_lat, max_lon, max_lat = gdf.total_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2b94c",
   "metadata": {},
   "source": [
    "## Initializing the RasterFlow client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4534b-5ca6-448f-8215-c4a97c410452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from rasterflow_remote import RasterflowClient\n",
    "\n",
    "from rasterflow_remote.data_models import (\n",
    "    ModelRecipes, \n",
    "    VectorizeMethodEnum\n",
    ")\n",
    "\n",
    "rf_client = RasterflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e414dee",
   "metadata": {},
   "source": [
    "## Running a model\n",
    "\n",
    "RasterFlow has pre-defined workflows to simplify orchestration of the processing steps for model inference.  These steps include:\n",
    "* Ingesting imagery for the specified Area of Interest (AOI)\n",
    "* Generating a seamless image from multiple image tiles (a mosaic) \n",
    "* Running inference with the selected model\n",
    "\n",
    "The output is a Zarr store of the model outputs.\n",
    "\n",
    "Note: This step will take approximately 30 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = rf_client.build_and_predict_mosaic_recipe(\n",
    "    # Path to our AOI in GeoParquet or GeoJSON format\n",
    "    aoi = aoi_path,\n",
    "\n",
    "    # Date range for imagery to be used by the model\n",
    "    start = datetime(2023, 1, 1),\n",
    "    end = datetime(2024, 1, 1),\n",
    "\n",
    "    # Coordinate Reference System EPSG code for the output mosaic   \n",
    "    crs_epsg = 3857,\n",
    "\n",
    "    # The model recipe to be used for inference (FTW in this case)\n",
    "    model_recipe = ModelRecipes.FTW,\n",
    ")\n",
    "\n",
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6fc2ab",
   "metadata": {},
   "source": [
    "## Visualize a subset of the model outputs\n",
    "The raster outputs from the model for this AOI are approximately 1GB.  We can choose a small subset of the data around the Plymell, Kansas and use hvplot to visualize the model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263eed28-9e56-49e7-ba42-9426aff0c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for visualization and coordinate transformation\n",
    "import hvplot.xarray\n",
    "import xarray as xr\n",
    "import s3fs \n",
    "import zarr\n",
    "from pyproj import Transformer\n",
    "from holoviews.element.tiles import EsriImagery \n",
    "\n",
    "# Open the Zarr store\n",
    "fs = s3fs.S3FileSystem(profile=\"default\", asynchronous=True)\n",
    "zstore = zarr.storage.FsspecStore(fs, path=model_outputs[5:])\n",
    "ds = xr.open_zarr(zstore)\n",
    "\n",
    "# Create a transformer to convert from lat/lon to meters\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True)\n",
    "\n",
    "# Transform boudning box coordinates from lat/lon to meters\n",
    "(min_x, max_x), (min_y, max_y) = transformer.transform(\n",
    "    [min_lon, max_lon], \n",
    "    [min_lat, max_lat]\n",
    ")\n",
    "\n",
    "# Select the height variable and slice the dataset to the bounding box\n",
    "# y=slice(max_y, min_y) handles the standard \"North-to-South\" image orientation\n",
    "ds_subset = ds.sel(band=\"field_boundaries\",\n",
    "    x=slice(min_x, max_x), \n",
    "    y=slice(max_y, min_y) \n",
    ")\n",
    "\n",
    "# Select the first time step and extract the variables array\n",
    "arr_subset = ds_subset.isel(time=0)[\"variables\"]\n",
    "\n",
    "# Create a base map layer using Esri satellite imagery\n",
    "base_map = EsriImagery()\n",
    "\n",
    "# Create an overlay layer from the model outputs with hvplot\n",
    "output_layer = arr_subset.hvplot(\n",
    "    x = \"x\",\n",
    "    y = \"y\",\n",
    "    geo = True,           # Enable geographic plotting\n",
    "    dynamic = True,       # Enable dynamic rendering for interactivity\n",
    "    rasterize = True,     # Use datashader for efficient rendering of large datasets\n",
    "    cmap = \"viridis\",     # Color map for visualization\n",
    "    aspect = \"equal\",     # Maintain equal aspect ratio\n",
    "    title = \"FTW Model Outputs\" \n",
    ").opts(\n",
    "    width = 600, \n",
    "    height = 600,\n",
    "    alpha = 0.7           # Set transparency to see the base map underneath\n",
    ")\n",
    "\n",
    "# Combine the base map and output layer\n",
    "final_plot = base_map * output_layer\n",
    "final_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4106b",
   "metadata": {},
   "source": [
    "## Vectorize the raster model outputs\n",
    "The output for the FTW model is a raster with three classes as bands: field, field_boundaries, and non_field_background.  \n",
    "\n",
    "We will run a seperate flow to convert the fields and field boundaries into vector geometries.  Converting these results to geometries allows us to more easily post process the results or join the results with other vector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0084f2a-74e0-4191-ad90-fb7047b564fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the classes that are predicted by the model\n",
    "model_features = xr.open_zarr(zstore)['band'].data.tolist()\n",
    "\n",
    "# Remove the 'non_field_background' class for vectorization\n",
    "vector_features = [f for f in model_features if f != 'non_field_background']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f41cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this should take about 5 minutes to complete\n",
    "vectorized_results = rf_client.vectorize_mosaic(\n",
    "        store = model_outputs,\n",
    "        features = vector_features,\n",
    "        threshold = 0.5,\n",
    "        vectorize_method = VectorizeMethodEnum.SEMANTIC_SEGMENTATION_RASTERIO,\n",
    "        vectorize_config={\"stats\": True, \"medial_skeletonize\": False}\n",
    "    )\n",
    "\n",
    "print(vectorized_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd7fcd6-19fa-49f8-bb03-de062f39f4ca",
   "metadata": {},
   "source": [
    "## Save the vectorized results to the catalog\n",
    "We can store these vectorized outputs in the catalog by using WherobotsDB to persist the GeoParquet results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954fa1e-7441-45bb-96bd-2cb8f70aa3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "config = SedonaContext.builder().getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107085f-c3fe-4c00-8810-22c6247139f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedona.sql(\"CREATE DATABASE IF NOT EXISTS org_catalog.ftw_db\")\n",
    "\n",
    "vectorize_result_df = sedona.read.format(\"geoparquet\").load(vectorized_results)\n",
    "vectorize_result_df = vectorize_result_df.withColumnRenamed(\"label\", \"layer\")\n",
    "vectorize_result_df.writeTo(\"org_catalog.ftw_db.ftw_vectorized\").createOrReplace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4571d",
   "metadata": {},
   "source": [
    "## Visualize the vectorized results\n",
    "To visualize the vectorized results, we will show the fields around Plymell, Kansas and filter out results with a score lower than 0.5. This threshold was determined through observation to strike a balance: it eliminates obvious noise without being overly aggressive, ensuring that we don't accidentally filter out too many relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark.sql.st_constructors import ST_GeomFromText\n",
    "from sedona.spark.sql.st_predicates import ST_Intersects\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "# Bounding box for Plymell, Kansas\n",
    "plymell_wkt = \"POLYGON ((-100.98 37.83, -100.98 37.68, -100.8 37.68, -100.8 37.83, -100.98 37.83))\"\n",
    "vectorize_result_filtered_df = vectorize_result_df.filter(\"layer == 'field'\").filter(\"score_mean > 0.5\") \\\n",
    "    .filter(ST_Intersects(f.col(\"geometry\"), ST_GeomFromText(lit(plymell_wkt))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9bb59f-0d2a-4def-9c93-51a0d73905ef",
   "metadata": {},
   "source": [
    "We will apply some WherobotsDB vector post processing operations to refine the model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc74553-d0ae-4d9d-a739-5e0c50f76c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 0.00001\n",
    "decimal_places = 6  # roughly 10cm in lat/lon\n",
    "df = vectorize_result_filtered_df.withColumn(\"geometry\", f.expr(\"ST_MakeValid(geometry)\"))\n",
    "df = df.withColumn(\"geometry\", f.expr(\"ST_SetSRID(geometry, 4326)\")) # vectorize_mosaic defaults to returning geometries in the CRS EPSG:4326\n",
    "df = df.withColumn(\"geometry\", f.expr(f\"ST_ReducePrecision(geometry, {decimal_places})\"))\n",
    "df = df.withColumn(\"geometry\", f.expr(f\"ST_SimplifyPreserveTopology(geometry, {tolerance})\"))\n",
    "df = df.repartition(200)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark.maps.SedonaKepler import SedonaKepler\n",
    "map = SedonaKepler.create_map(df=df, name=\"Vectorized results\")\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217c902",
   "metadata": {},
   "source": [
    "## Generate PM Tiles for visualization\n",
    "To improve visualization performance of a large number of geometries, we can use Wherobots built-in high performance PM tile generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6919ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wherobots import vtiles\n",
    "full_tiles_path = os.getenv(\"USER_S3_PATH\") + \"tiles.pmtiles\"\n",
    "vtiles.generate_pmtiles(df, full_tiles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec582b8a-082b-4bfd-a85f-22c4bb69718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtiles.show_pmtiles(full_tiles_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61980171-a74d-4849-a77a-34fad589c879",
   "metadata": {},
   "source": [
    "## Sharing PMTiles results with the Wherobots PMTiles Viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0832d69-a594-4f1d-8c3b-a9692f95bf71",
   "metadata": {},
   "source": [
    "You can generate a pre-signed url to your pmtiles using `get_url`.\n",
    "\n",
    "Then, copy this to your clipboard with right-click + \"Copy Output to Clipboard\".\n",
    "\n",
    "You can paste this url into https://tile-viewer.wherobots.com/ and create a publicly accessible PMTiles map served from your own bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8444bd-e4c9-4c10-9c89-386c5d48c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wherobots.tools.utility.s3_utils import get_url\n",
    "\n",
    "get_url(full_tiles_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e79110",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. **Kerner, H., Chaudhari, S., Ghosh, A., Robinson, C., Ahmad, A., Choi, E., Jacobs, N., Holmes, C., Mohr, M., et al. (2024).** Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation. *arXiv preprint arXiv:2409.16252*. Accepted at AAAI-2025 Artificial Intelligence for Social Impact (AISI) track."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
