{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37fe0da",
   "metadata": {},
   "source": [
    "![](https://wherobots.com/wp-content/uploads/2023/12/Inline-Blue_Black_onWhite@3x.png)\n",
    "\n",
    "## WherobotsAI Raster Inference - Segmentation \n",
    "\n",
    "This example demonstrates query inference using a segmentation model with Raster Inference to identify solar farms in satellite imagery. We will use a machine learning model from [Satlas](https://satlas.allen.ai/ai) <sup>1</sup> which was trained using imagery from the European Space Agencyâ€™s Sentinel-2 satellites.\n",
    "\n",
    "**Note: This notebook requires the Wherobots Inference functionality to be enabled and a GPU runtime selected in Wherobots Cloud. Please [contact us](https://wherobots.com/contact/) to enable these features.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fec939-6e1a-486a-93ec-d6ac7a7b9aaa",
   "metadata": {},
   "source": [
    "### Step 1: Set Up The WherobotsDB Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sedona.spark import SedonaContext\n",
    "\n",
    "config = SedonaContext.builder().appName('segmentation-batch-inference')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654ce00-87ec-4200-88ac-feac99575490",
   "metadata": {},
   "source": [
    "### 2: Load Satellite Imagery\n",
    "\n",
    "Next, we load the satellite imagery that we will be running inference over. These GeoTiff images are loaded as *out-db* rasters from the Wherobots Open Data Catalog, where each row represents a different scene.\n",
    "\n",
    "If your inference rasters are not in a Wherobots catalog, you can load them using the following code:\n",
    "```python\n",
    "tif_folder_path = 's3a://wherobots-benchmark-prod/data/ml/satlas/'\n",
    "df_raster_input = sedona.read.format(\"raster\").load(f\"{tif_folder_path}/*.tiff\").sample(.05)\n",
    "df_raster_input.createOrReplaceTempView(\"df_raster_input\")\n",
    "df_raster_input.show(truncate=False)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac10af4-5ccf-43bb-8aaf-947d01c3fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raster_input = sedona.table(f\"wherobots_pro_data.satlas.solar_satlas\").sample(.05)\n",
    "df_raster_input.createOrReplaceTempView(\"df_raster_input\")\n",
    "df_raster_input.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e55013-053f-4de6-b88f-1ca0b31a0ada",
   "metadata": {},
   "source": [
    "### 3: Run Predictions And Visualize Results\n",
    "\n",
    "To run predictions we will specify the model we wish to use. Some models are pre-loaded and made available in Wherobots Cloud. We can also load our own models. Predictions can be run with the Raster Inference SQL function [`RS_Segment`](https://docs.wherobots.com/latest/api/wherobots-inference/pythondoc/inference/sql_functions/) or the Python API.\n",
    "\n",
    "Here we generate 400 raster predictions using `RS_Segment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4399933-2da4-4254-bfb3-aea354c3443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'solar-satlas-sentinel2'\n",
    "\n",
    "predictions_df = sedona.sql(f\"\"\"\n",
    "SELECT\n",
    "  rast,\n",
    "  segment_result.*\n",
    "FROM (\n",
    "  SELECT\n",
    "    rast,\n",
    "    RS_SEGMENT('{model_id}', rast) AS segment_result\n",
    "  FROM\n",
    "    df_raster_input\n",
    ") AS segment_fields\n",
    "\"\"\")\n",
    "\n",
    "predictions_df.cache().count()\n",
    "predictions_df.show()\n",
    "predictions_df.createOrReplaceTempView(\"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a2bf5-ea20-400b-8b3a-cc3ea0b7ad88",
   "metadata": {},
   "source": [
    "Now that we've generated predictions using our model over our satellite imagery, we can use the `RS_Segment_To_Geoms` function to extract the geometries indicating the model has identified as possible solar farms. we'll specify the following:\n",
    "\n",
    "* a raster column to use for georeferencing our results\n",
    "* the prediction result from the previous step\n",
    "* our category label \"1\" returned by the model representing Solar Farms and the class map to use for assigning labels to the prediction\n",
    "* a confidence threshold between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad63ec-3f82-42de-835e-b16601de1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multipolys = sedona.sql(\"\"\"\n",
    "    WITH t AS (\n",
    "        SELECT RS_SEGMENT_TO_GEOMS(rast, confidence_array, array(1), class_map, 0.65) result\n",
    "        FROM predictions\n",
    "    )\n",
    "    SELECT result.* FROM t\n",
    "\"\"\")\n",
    "\n",
    "df_multipolys.cache().count()\n",
    "df_multipolys.show()\n",
    "df_multipolys.createOrReplaceTempView(\"multipolygon_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd554156",
   "metadata": {},
   "source": [
    "Since we ran inference across the state of Arizona, many scenes don't contain solar farms and don't have positive detections. Let's filter out scenes without segmentation detections so that we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4936d2-723b-4613-bf4e-d1fe3f1f8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_predictions = sedona.sql(\"\"\"\n",
    "    SELECT\n",
    "        element_at(class_name, 1) AS class_name,\n",
    "        cast(element_at(average_pixel_confidence_score, 1) AS double) AS average_pixel_confidence_score,\n",
    "        ST_Collect(geometry) AS merged_geom\n",
    "    FROM\n",
    "        multipolygon_predictions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f5143-d6ac-49db-9d44-ad60eaafefb8",
   "metadata": {},
   "source": [
    "This leaves us with a few predicted solar farm polygons for our 300 satellite image samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab528c-51e8-43ee-ba5f-981d50c20f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_predictions = df_merged_predictions.filter(\"ST_IsEmpty(merged_geom) = False\")\n",
    "df_filtered_predictions.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45731d3-eed9-436b-b2cc-095a73882827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8269f80",
   "metadata": {},
   "source": [
    "We'll plot these with SedonaKepler. Compare the satellite basemap with the predictions and see if there's a match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153615b-83e8-4a7b-8f21-efea59a93808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "\n",
    "map = SedonaKepler.create_map()\n",
    "\n",
    "SedonaKepler.add_df(map, df=df_filtered_predictions, name=\"Solar Farm Detections\")\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952aaa1-9479-4bc5-98bc-461bc604bf48",
   "metadata": {},
   "source": [
    "### wherobots.inference Python API\n",
    "\n",
    "If you prefer python, wherobots.inference offers a module for registering the SQL inference functions as python functions. Below we run the same inference as before with RS_SEGMENT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e631a91-6837-4bfe-a50f-6968eaac6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wherobots.inference.engine.register import create_semantic_segmentation_udfs\n",
    "from pyspark.sql.functions import col\n",
    "rs_segment, rs_text_to_segments =  create_semantic_segmentation_udfs(batch_size = 9, sedona=sedona)\n",
    "df = df_raster_input.withColumn(\"segment_result\", rs_segment(model_id, col(\"rast\"))).select(\n",
    "                               \"rast\",\n",
    "                               col(\"segment_result.confidence_array\").alias(\"confidence_array\"),\n",
    "                               col(\"segment_result.class_map\").alias(\"class_map\")\n",
    "                           )\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f379e56-6fdf-4825-9bb7-024781dea77d",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Bastani, Favyen, Wolters, Piper, Gupta, Ritwik, Ferdinando, Joe, and Kembhavi, Aniruddha. \"SatlasPretrain: A Large-Scale Dataset for Remote Sensing Image Understanding.\" *arXiv preprint arXiv:2211.15660* (2023). [https://doi.org/10.48550/arXiv.2211.15660](https://doi.org/10.48550/arXiv.2211.15660)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
