{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Wherobots logo](../assets/img/header-logo.png)\n",
    "\n",
    "# WherobotsAI Raster Inference (Text-Prompted Models)\n",
    "\n",
    "In this notebook we introduce text-prompted Raster Inference in WherobotsAI, powered by Meta AI’s SAM2 and Google DeepMind’s OWLv2 models. Raster Inference brings the ability to run advanced vision models directly on large-scale satellite imagery, turning pixels into analysis-ready vector features at scale.  \n",
    "\n",
    "We will demonstrate how to apply these models to NAIP imagery of Miami Airport, using `RS_Text_to_BBoxes` (OWLv2) for object detection and `RS_Text_to_Segments` (SAM2) for segmentation.  \n",
    "\n",
    "[Read more about Wherobots Raster Inference in the documentation](https://docs.wherobots.com/latest/tutorials/wherobotsai/wherobots-inference/raster-inference-overview/?h=raster+inference).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sedona context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "config = SedonaContext.builder().getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NAIP imagery for Miami Airport\n",
    "\n",
    "We will use the native raster reader to load GeoTIFFs as out-of-database or \"out-db\" rasters and perform dyanamic tiling on read.\n",
    "Spliting the large GeoTIFF into small tiles improves the distribution of workload across the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"s3://wherobots-examples/data/naip/miami-airport.tiff\"\n",
    "tile_size = 256\n",
    "\n",
    "df = sedona.read.format(\"raster\")\\\n",
    "        .option(\"tileWidth\", tile_size)\\\n",
    "        .option(\"tileHeight\", tile_size)\\\n",
    "        .load(url)\n",
    "\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Raster Inputs\n",
    "\n",
    "Before running inference, it’s useful to explore the imagery itself.  \n",
    "We’ll visualize the footprints of the raster tiles with SedonaKepler and preview a few raw images using SedonaUtils. This gives us confidence that the data is being read correctly and aligned spatially before applying any models.\n",
    "\n",
    "> Tip: You can also save the Kepler map as an interactive HTML file with `kepler_map.save_to_html()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_map = SedonaKepler.create_map()\n",
    "df = df.withColumn('footprint', expr(\"ST_TRANSFORM(RS_CONVEXHULL(rast),'EPSG:4326')\"))\n",
    "SedonaKepler.add_df(kepler_map, df=df, name=\"Image Footprints\")\n",
    "\n",
    "kepler_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlDf = sedona.sql(f\"\"\"SELECT RS_AsImage(rast, 250) as FROM df limit 5\"\"\")\n",
    "SedonaUtils.display_image(htmlDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running segementation using SAM2 model\n",
    "\n",
    "Now we’ll run inference over the raster tiles using Wherobots SQL function `RS_Text_to_Segments()`.\n",
    "\n",
    "For this example, we specify the following parameters -\n",
    "- Model: `\"sam2\"`\n",
    "- Text prompt: `\"airplanes\"`\n",
    "- Confidence threshold: `0.5`\n",
    "\n",
    "The confidence threshold controls which detections are returned (scores range from 0 to 1).  \n",
    "For this particular model, most positives have confidence scores of at most ~0.7, so we start with `0.5` to favor **recall** on this model/dataset. This helps us understand how the model performs before tightening the threshold later.\n",
    "\n",
    "The function returns predicted segments for each raster in our region of interest.\n",
    "We’ll cache the results for efficiency and register them as a temporary view so we can explore them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sam2\"\n",
    "prompt = \"airplanes\"\n",
    "threshold = 0.5\n",
    "\n",
    "preds = sedona.sql(f\"\"\"\n",
    "    SELECT \n",
    "        rast, \n",
    "        RS_TEXT_TO_SEGMENTS(\n",
    "            '{model_id}', \n",
    "            rast, \n",
    "            '{prompt}', \n",
    "            {threshold}\n",
    "        ) AS preds \n",
    "    FROM df\n",
    "\"\"\")\n",
    "\n",
    "preds.cache().count()\n",
    "preds.createOrReplaceTempView(\"preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Results\n",
    "\n",
    "The raw inference output contains arrays of predictions (segments, confidence scores, and labels) for each raster tile.  \n",
    "Before plotting, we need to flatten these arrays so that each row corresponds to a single prediction.\n",
    "\n",
    "We’ll:  \n",
    "1. Filter out empty or invalid results.  \n",
    "2. Use `arrays_zip` + `explode` to turn lists of predictions into individual rows.  \n",
    "3. Keep the geometry, confidence score, and label for each detected object.  \n",
    "\n",
    "This prepares the data for mapping and analysis with SedonaKepler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_filtered = sedona.sql(f\"\"\"\n",
    "  SELECT *\n",
    "  FROM preds\n",
    "  WHERE\n",
    "    size(preds.labels) > 0\n",
    "    AND array_contains(preds.labels, 1)\n",
    "    AND NOT array_contains(preds.segments_wkt, 'POLYGON EMPTY')\n",
    "\"\"\")\n",
    "\n",
    "preds_filtered.createOrReplaceTempView(\"preds_filtered\")\n",
    "preds_filtered.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded = sedona.sql(\"\"\"\n",
    "    SELECT\n",
    "        rast,\n",
    "        exploded_predictions.*\n",
    "    FROM\n",
    "        preds_filtered\n",
    "    LATERAL VIEW explode(arrays_zip(preds.segments_wkt, preds.confidence_scores, preds.labels)) AS exploded_predictions\n",
    "    WHERE\n",
    "        exploded_predictions.confidence_scores != 0.0\n",
    "\"\"\")\n",
    "exploded.cache().count()\n",
    "exploded.createOrReplaceTempView(\"exploded\")\n",
    "exploded.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing segmentation results\n",
    "\n",
    "Let’s map the predicted segments to sanity-check geometry and coverage.\n",
    "We’ll add the detections as a layer in SedonaKepler—use the tooltip to inspect confidence per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_map = SedonaKepler.create_map()\n",
    "SedonaKepler.add_df(kepler_map, df=exploded, name=\"Airplane Detections\")\n",
    "\n",
    "kepler_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay results on source imagery\n",
    "\n",
    "To see detections on top of the underlying rasters, use `show_detections`.\n",
    "It expects the non-exploded predictions (arrays per tile) and can filter by confidence.\n",
    "\n",
    "> Tip: show_detections works with DataFrames that still have the raster column and arrays of results; exploded DataFrames aren’t supported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked_preds_df = sedona.sql(\"\"\"\n",
    "  SELECT\n",
    "    rast,\n",
    "    preds.segments_wkt,\n",
    "    preds.confidence_scores,\n",
    "    preds.labels\n",
    "  FROM preds_filtered\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wherobots.inference.plot.detections import show_detections\n",
    "\n",
    "show_detections(\n",
    "    unpacked_preds_df,\n",
    "    confidence_threshold=0.7,\n",
    "    plot_geoms=True,\n",
    "    geometry_column=\"segments_wkt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Object Detection using OWLv2 model\n",
    "\n",
    "Now we’ll run inference over the raster tiles using Wherobots’ SQL function `RS_Text_to_BBoxes()`.\n",
    "\n",
    "For this example, we specify the following parameters –\n",
    "- Model: `\"owlv2\"`\n",
    "- Text prompt: `\"airplanes\"`\n",
    "- Confidence threshold: `0.5`\n",
    "\n",
    "The function returns predicted bounding boxes for each raster in our region of interest.\n",
    "\n",
    "We’ll cache the results for efficiency and register them as a temporary view so we can explore them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"owlv2\"\n",
    "prompt = \"airplanes\"\n",
    "threshold = 0.5\n",
    "\n",
    "preds = sedona.sql(f\"\"\"\n",
    "    SELECT \n",
    "        rast, \n",
    "        RS_TEXT_TO_BBoxes(\n",
    "            '{model_id}', \n",
    "            rast, \n",
    "            '{prompt}', \n",
    "            {threshold}\n",
    "        ) AS preds \n",
    "    FROM df\n",
    "\"\"\")\n",
    "preds.cache().count()\n",
    "preds.createOrReplaceTempView(\"preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Results\n",
    "\n",
    "The raw inference output contains arrays of predictions (bounding boxes, confidence scores, and labels) for each raster tile.  \n",
    "Before plotting, we need to flatten these arrays so that each row corresponds to a single prediction.\n",
    "\n",
    "We’ll:  \n",
    "1. Filter out empty or invalid results.  \n",
    "2. Use `arrays_zip` + `explode` to turn lists of predictions into individual rows.  \n",
    "3. Keep the geometry, confidence score, and label for each detected object.  \n",
    "\n",
    "This prepares the data for mapping and analysis with SedonaKepler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_filtered = sedona.sql(f\"\"\"\n",
    "  SELECT *\n",
    "  FROM preds\n",
    "  WHERE\n",
    "    size(preds.labels) > 0\n",
    "    AND array_contains(preds.labels, 1)\n",
    "    AND NOT array_contains(preds.bboxes_wkt, 'POLYGON EMPTY')\n",
    "\"\"\")\n",
    "preds_filtered.createOrReplaceTempView(\"preds_filtered\")\n",
    "preds_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each raster tile returns multiple predictions as arrays.  \n",
    "We use `explode` to flatten these arrays so every detected object becomes its own row for easier mapping and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded = sedona.sql(\"\"\"\n",
    "    SELECT\n",
    "        rast,\n",
    "        exploded_predictions.*\n",
    "    FROM\n",
    "        preds_filtered\n",
    "    LATERAL VIEW explode(arrays_zip(preds.bboxes_wkt, preds.confidence_scores, preds.labels)) AS exploded_predictions\n",
    "    WHERE\n",
    "        exploded_predictions.confidence_scores != 0.0\n",
    "\"\"\")\n",
    "exploded.cache().count()\n",
    "exploded.createOrReplaceTempView(\"exploded\")\n",
    "exploded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Object Detection results\n",
    "\n",
    "Let’s map the predicted Airplane bboxes to sanity-check geometry and coverage.\n",
    "We’ll add the detections as a layer in SedonaKepler—use the tooltip to inspect confidence per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_map = SedonaKepler.create_map()\n",
    "SedonaKepler.add_df(kepler_map, df=exploded, name=\"Airplane Detections\")\n",
    "\n",
    "kepler_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay results on source imagery\n",
    "\n",
    "To see detections on top of the underlying rasters, use `show_detections`.\n",
    "It expects the non-exploded predictions (arrays per tile) and can filter by confidence.\n",
    "\n",
    "> Tip: show_detections works with DataFrames that still have the raster column and arrays of results; exploded DataFrames aren’t supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked_preds_df = sedona.sql(\"\"\"\n",
    "  SELECT\n",
    "    rast,\n",
    "    preds.bboxes_wkt,\n",
    "    preds.confidence_scores,\n",
    "    preds.labels\n",
    "  FROM preds_filtered\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see below that OWLv2 and SAM2 do remarkably well at identifying airplanes with little user effort! Previously, achieving similar results was a significant undertaking. An entire Machine Learning engineering team would have needed to build such a model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wherobots.inference.plot.detections import show_detections\n",
    "\n",
    "show_detections(\n",
    "    unpacked_preds_df,\n",
    "    confidence_threshold=0.5,\n",
    "    plot_geoms=True,\n",
    "    side_by_side=False,\n",
    "    geometry_column=\"bboxes_wkt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps with Raster Inference\n",
    "\n",
    "With access to general-purpose, text-promptable models, what will you predict and georeference next?\n",
    "\n",
    "Some ideas on next steps to try, include:\n",
    "\n",
    "* Predicting different objects next to the airplanes in the image tiles above using new text prompts.\n",
    "* Adjusting the confidence score threshold for `RS_Text_to_Segments` or `RS_Text_to_BBoxes` to see how SAM2 or OWLv2 respond.\n",
    "* Loading a new imagery dataset with our [STAC Reader](https://docs.wherobots.com/latest-snapshot/references/wherobotsdb/vector-data/Stac/) and try to predict a different feature of interest, such as agriculture, buildings, or tree crowns.\n",
    "\n",
    "We're excited to hear about what you're doing with SAM2 and OWLv2! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
