{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://wherobots.com/wp-content/uploads/2023/12/Inline-Blue_Black_onWhite.png)\n",
    "# <span style=\"color: #7b73e2;\">WherobotsAI Raster Inference - Predicting Bounding Boxes and Segments of Airplanes from an LLM-based Text Query</span>\n",
    "\n",
    "\n",
    "#### This example demonstrates two models that predict objects from text queries: Segment Anything 2 (SAM2) and Open Vocabulary Object Detection (OWLv2) from Google Deepmind. We'll use these models in **Raster Inference** to identify <span style=\"color: #7b73e2;\">**commercial airplanes**</span> over Miami airport in arial imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: #7b73e2;\" >Start WherobotsDB</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T20:53:41.665223Z",
     "iopub.status.busy": "2025-04-09T20:53:41.665007Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from sedona.spark import SedonaContext\n",
    "from sedona.raster_utils.SedonaUtils import SedonaUtils\n",
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "config = (\n",
    "    SedonaContext.builder()\n",
    "    .config(\"spark.wherobots.inference.args\", \"2\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: #7b73e2;\">Load Satellite Imagery Efficiently</span>\n",
    "\n",
    "In this step, we load the satellite imagery to run <span style=\"color: #7b73e2;\">**inference**</span> over. \n",
    "The large Miami airport GeoTIFF image is split into tiles and loaded as <span style=\"color: #7b73e2;\">**out-of-database or \"out-db\" rasters**</span> in **WherobotsDB**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"s3://wherobots-examples/data/naip/miami-airport.tiff\"\n",
    "tile_size = 256\n",
    "df = sedona.read.format(\"raster\").option(\"tileWidth\", tile_size).option(\"tileHeight\", tile_size).load(url)\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: #7b73e2;\">Viewing the Model's Imagery Inputs</span>\n",
    "\n",
    "We can see the footprints of the tiled images with the `SedonaKepler.create_map()` integration. Using `SedonaUtils.display_image()` we can view the images as well.\n",
    "\n",
    "<span style=\"color: #7b73e2;;\"> **Tip:** </span>  Save the map to a html file using `kepler_map.save_to_html()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_map = SedonaKepler.create_map()\n",
    "df = df.withColumn('footprint', expr(\"ST_TRANSFORM(RS_CONVEXHULL(rast),'EPSG:4326')\"))\n",
    "SedonaKepler.add_df(kepler_map, df=df, name=\"Image Footprints\")\n",
    "\n",
    "kepler_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlDf = sedona.sql(f\"\"\"SELECT RS_AsImage(rast, 250) as FROM df limit 5\"\"\")\n",
    "SedonaUtils.display_image(htmlDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T19:54:39.609555Z",
     "iopub.status.busy": "2025-04-09T19:54:39.609133Z",
     "iopub.status.idle": "2025-04-09T19:54:39.615438Z",
     "shell.execute_reply": "2025-04-09T19:54:39.614658Z",
     "shell.execute_reply.started": "2025-04-09T19:54:39.609537Z"
    }
   },
   "source": [
    "## <span style=\"color: #7b73e2;\">Run Predictions and Visualize Results</span>\n",
    "\n",
    "To run predictions, specify the model to use by the `model id`. Five models are pre-loaded and made available in **Wherobots Cloud**. You can also load your own models, learn more about that process [here](https://docs.wherobots.com/latest/tutorials/wherobotsai/wherobots-inference/raster-inference-overview/?h=bring#bring-your-own-model-guide).\n",
    "\n",
    "Inference can be run using **Wherobots' Spatial SQL functions**, in this case: `RS_Text_to_Segments()`.\n",
    "            \n",
    "Here we generate predictions for all images in the ROI. The predictions output has one label for the text prompt, `1` for a positive prediction. \n",
    "\n",
    "Then filter and print some of the results to see how positive detect results look.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sam2\"\n",
    "prompt = \"airplanes\"\n",
    "threshold = 0.5\n",
    "\n",
    "preds = sedona.sql(\n",
    "    f\"\"\"SELECT rast, RS_TEXT_TO_SEGMENTS('{model_id}', rast, '{prompt}', {threshold}) AS preds from df\"\"\"\n",
    ")\n",
    "preds.cache().count()\n",
    "preds.createOrReplaceTempView(\"preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: #7b73e2;\">Prepare Results</span>\n",
    "\n",
    "Before plotting our predictions we need to transform our results. \n",
    "\n",
    "We need our table in a structure where each row represents _all_ of a raster scene's bounding box predictions to a format where each row represents a _single_ predicted bounding box. \n",
    "\n",
    "To do this, combine the list columns containing our prediction results (`max_confidence_bboxes`, `max_confidence_scores`, and `max_confidence_labels`) with `arrays_zip`.  Then use `explode` to convert lists to rows. \n",
    "\n",
    "To map the results with `SedonaKepler`, convert the `max_confidence_bboxes` column to a `GeometryType` column with `ST_GeomFromWKT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_filtered = sedona.sql(f\"\"\"\n",
    "  SELECT *\n",
    "  FROM preds\n",
    "  WHERE\n",
    "    size(preds.labels) > 0\n",
    "    AND array_contains(preds.labels, 1)\n",
    "    AND NOT array_contains(preds.segments_wkt, 'POLYGON EMPTY')\n",
    "\"\"\")\n",
    "preds_filtered.createOrReplaceTempView(\"preds_filtered\")\n",
    "preds_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded = sedona.sql(\"\"\"\n",
    "SELECT\n",
    "    rast,\n",
    "    exploded_predictions.*\n",
    "FROM\n",
    "    preds_filtered\n",
    "LATERAL VIEW explode(arrays_zip(preds.segments_wkt, preds.confidence_scores, preds.labels)) AS exploded_predictions\n",
    "WHERE\n",
    "    exploded_predictions.confidence_scores != 0.0\n",
    "\"\"\")\n",
    "exploded.cache().count()\n",
    "exploded.createOrReplaceTempView(\"exploded\")\n",
    "exploded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: #7b73e2;\">Viewing Model Results: Airplane Segmentation Predictions</span>\n",
    "\n",
    "Just like we visualized the footprints of the tiled images earlier, we can also view our prediction geometries! Highlight a prediction to view it's confidence score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_map = SedonaKepler.create_map()\n",
    "SedonaKepler.add_df(kepler_map, df=exploded, name=\"Airplane Detections\")\n",
    "\n",
    "kepler_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view results on the underlying imagery used by the model, you can use the `show_detections` function. This function accepts a Dataframe containing an outdb_raster column as well as other arguments to control the plot result. Check out the full docs for the function by calling `show_detections??`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wherobots.inference.plot.detections import show_detections\n",
    "show_detections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked_preds_df = sedona.sql(\"SELECT rast, preds.* FROM preds_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_detections(\n",
    "    unpacked_preds_df,\n",
    "    confidence_threshold=0.7,\n",
    "    plot_geoms=True,\n",
    "    geometry_column=\"segments_wkt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: #7b73e2;\">Running Object Detection with a Text Prompt</span>\n",
    "\n",
    "We can also get bounding box predictions instead of segments using `RS_Text_To_BBoxes`. BBoxes, or boundign boxes, are more useful when you are only concerned with counting and localizing objects rather than delineating exact shape and area with `RS_Text_To_Segments`.\n",
    "\n",
    "Each of the steps for `RS_Text_To_BBoxes` are the same as `RS_TExt_To_Segments` for generating predictions. The only two changes we need to make are\n",
    "\n",
    "* using a different hosted model id: `owlv2` instead of `sam2`\n",
    "* changing our SQL queries that work with the prediction results to work with `bboxes_wkt` column instead of the `segments_wkt` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"owlv2\"\n",
    "prompt = \"airplanes\"\n",
    "threshold = 0.5\n",
    "\n",
    "preds = sedona.sql(\n",
    "    f\"\"\"SELECT rast, RS_TEXT_TO_BBoxes('{model_id}', rast, '{prompt}', {threshold}) AS preds from df\"\"\"\n",
    ")\n",
    "preds.cache().count()\n",
    "preds.createOrReplaceTempView(\"preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before, we'll filter predictions by labels, remove empty predictions, and show the results in a browsable map and on top of the original imagery for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_filtered = sedona.sql(f\"\"\"\n",
    "  SELECT *\n",
    "  FROM preds\n",
    "  WHERE\n",
    "    size(preds.labels) > 0\n",
    "    AND array_contains(preds.labels, 1)\n",
    "    AND NOT array_contains(preds.bboxes_wkt, 'POLYGON EMPTY')\n",
    "\"\"\")\n",
    "preds_filtered.createOrReplaceTempView(\"preds_filtered\")\n",
    "preds_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded = sedona.sql(\"\"\"\n",
    "SELECT\n",
    "    rast,\n",
    "    exploded_predictions.*\n",
    "FROM\n",
    "    preds_filtered\n",
    "LATERAL VIEW explode(arrays_zip(preds.bboxes_wkt, preds.confidence_scores, preds.labels)) AS exploded_predictions\n",
    "WHERE\n",
    "    exploded_predictions.confidence_scores != 0.0\n",
    "\"\"\")\n",
    "exploded.cache().count()\n",
    "exploded.createOrReplaceTempView(\"exploded\")\n",
    "exploded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_map = SedonaKepler.create_map()\n",
    "SedonaKepler.add_df(kepler_map, df=exploded, name=\"Airplane Detections\")\n",
    "\n",
    "kepler_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked_preds_df = sedona.sql(\"SELECT rast, preds.* FROM preds_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see below that OWLv2 and SAM2 do remarkably well at identifying airplanes with little user effort! Before promptable, general-purpose models like these were available, it would be a significant project for an ML Engineering team to arrive at a similar result by developing a model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_detections(\n",
    "    unpacked_preds_df,\n",
    "    confidence_threshold=0.5,\n",
    "    plot_geoms=True,\n",
    "    side_by_side=False,\n",
    "    geometry_column=\"bboxes_wkt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: #7b73e2;\">Next Steps with Raster Inference</span>\n",
    "\n",
    "With access to general-purpose, text-promptable models, what will you predict and georeference next? Some ideas on next things to try include:\n",
    "\n",
    "* Try to predict different objects besides airplanes in the image tiles above using new text prompts\n",
    "* Adjust the confidence score threshold for `RS_Text_to_Segments` or `RS_Text_to_BBoxes` to see how SAM2 or OWLv2 respond\n",
    "* Read a new imagery dataset with our [STAC Reader](https://docs.staging.wherobots.com/latest-snapshot/references/wherobotsdb/vector-data/Stac/) and try to predict a different feature of interest, such as agriculture, buildings, or tree crowns.\n",
    "\n",
    "We're excited to hear what you're doing with SAM2 and OWLv2! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
