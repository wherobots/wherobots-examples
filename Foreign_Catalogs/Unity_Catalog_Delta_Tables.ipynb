{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dafd1d1",
   "metadata": {},
   "source": [
    "# Geospatial ETL with Wherobots and Databricks Unity Catalog\n",
    "\n",
    "This notebook builds a geospatial ETL pipeline using Wherobots and Databricks Unity Catalog.\n",
    "\n",
    "Using a weather forecast dataset, you will:\n",
    "\n",
    "* **Read** a Managed Delta table from Unity Catalog.\n",
    "* **Transform** coordinates into spatial `POINT` geometries.\n",
    "* **Enrich** the data by calculating each forecast's proximity to Tokyo to create a new \"threat\" feature.\n",
    "* **Write** the results back to a new external Delta table, dropping the geometry column as it is not natively supported by Databricks.\n",
    "    * This example writes to an External Delta table because Databricks prevents external platforms like Wherobots from writing to Managed tables. \n",
    "\n",
    "This notebook provides the building blocks for you to perform more complex spatial analysis and processing on your own data in Wherobots.\n",
    "\n",
    "The exercises in this notebook use the [Accuweather](https://marketplace.databricks.com/details/8c8ad63e-d96e-47d6-b56b-a42affbdb227/AccuWeather_Forecast-Weather-Data) `forecast_daily_calendar_imperial` table dataset, which comes pre-loaded in your Databricks workspace.\n",
    "\n",
    "> **Data Disclaimer:** Review the following about the dataset used in this notebook:\n",
    "> * The weather data used in this demonstration originates from the `samples.accuweather.forecast_daily_calendar_imperial` dataset provided within Databricks.\n",
    "> Wherobots is not responsible for the accuracy or completeness of this data.\n",
    "> * This analysis is based on daily forecast data and does not represent real-time conditions.\n",
    "> * For complete information about the dataset, go to [Forecast Weather Data](https://marketplace.databricks.com/details/8c8ad63e-d96e-47d6-b56b-a42affbdb227/AccuWeather_Forecast-Weather-Data) and click **Documentation** within the Product Links section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4889d4d6-9671-4435-a6e4-4a318a29f66e",
   "metadata": {},
   "source": [
    "##  Prerequisites\n",
    "\n",
    "In order to run this example notebook, you'll need an:\n",
    "\n",
    "- An **Existing Databricks catalog and schema governed** by Unity Catalog.\n",
    "    - Optionally, you can create a new [catalog](https://docs.databricks.com/aws/en/catalogs/create-catalog) and [schema](https://docs.databricks.com/aws/en/schemas/create-schema) in Databricks.\n",
    "- A **Connection** between Wherobots and your Unity Catalog-governed schema and catalog.\n",
    "    - For more information on connecting Unity Catalog to your Wherobots Organization, including the necessary Databricks catalog permissions, see [Connect to Unity Catalog](https://docs.wherobots.com/latest/get-started/initial-storage/connect-to-unity-catalog/).\n",
    "    - If your Unity Catalog has been successfully connected to Wherobots, you will be able to see it in the [**Wherobots Data Hub**](https://cloud.wherobots.com/data-hub).\n",
    "    - The permissions necessary to read and write Delta tables within a Databricks Unity Catalog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19e8dd",
   "metadata": {},
   "source": [
    "> **Note:** Wherobots discovers Databricks catalogs only at your runtime's initialization.\n",
    "> If you created a new Databricks catalog _after_ the Wherobots runtime was started, that catalog won't be visible until you restart the Wherobots runtime.\n",
    "\n",
    ">  To make a new catalog visible, complete the following steps to restart the runtime:\n",
    "\n",
    "> 1. **Save active work:** Ensure any running jobs or SQL sessions are saved.\n",
    "> 1. **Destroy runtime:** Stop the current Wherobots runtime in [Wherobots Cloud](https://cloud.wherobots.com/).\n",
    "> 1. **Start a new runtime:** Start the runtime again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887626d",
   "metadata": {},
   "source": [
    "## In a Databricks SQL editor\n",
    "\n",
    "Create a table in your Unity Catalog that copies the data provided by Accuweather's `samples.accuweather.forecast_daily_calendar_imperial` dataset.\n",
    "After copying this data into its own Delta table, you can query and modify it in Wherobots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b3441",
   "metadata": {},
   "source": [
    "### Include your Databricks resources\n",
    "\n",
    "Update the `YOUR-CATALOG` and `YOUR-SCHEMA` variables (maintaining the backticks around each) in the cell below to point to the resources in your Databricks environment where you have permission to create tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a81e4e",
   "metadata": {},
   "source": [
    "Run the following command in a **Databricks SQL editor** to create a new table with the necessary sample data from the built-in Accuweather sample data.\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TABLE `YOUR-CATALOG`.`YOUR-SCHEMA`.`forecast_daily_calendar_imperial_wbc_demo`\n",
    "\n",
    "USING DELTA\n",
    "AS\n",
    "SELECT *\n",
    "FROM `samples`.`accuweather`.`forecast_daily_calendar_imperial`\n",
    "LIMIT 10000;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d382615",
   "metadata": {},
   "source": [
    "Go to your Databricks SQL Workspace to confirm that a new Managed Delta table has been created in your intended location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef8287",
   "metadata": {},
   "source": [
    "## In a Wherobots notebook\n",
    "\n",
    "Run the following commands in this Wherobots notebook.\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0951440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import expr, col, when, lit\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c1990-a93c-43ff-9859-8c83fcff687e",
   "metadata": {},
   "source": [
    "### Create the SedonaContext\n",
    "\n",
    "The following imports the necessary modules from the Sedona library and creates a `SedonaContext` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b742941-25f6-4084-8e47-fd1f52e33472",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SedonaContext.builder().getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f46923-431b-489a-8bec-3a09ccd9242a",
   "metadata": {},
   "source": [
    "###  Set up Wherobots notebook variables\n",
    "\n",
    "Define the variables you'll use throughout this notebook.\n",
    "\n",
    "These variables define the key resources for the ETL pipeline for this notebook. \n",
    "\n",
    "Set the names for the Databricks catalog, schema, and the source and output tables you'll be using for reading and writing tables in this example.\n",
    "\n",
    "Additionally, define the S3 path for an external table location and create fully qualified names (FQN) for easier use in Spark SQL commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6e28a-c133-4fdb-be5d-9b273ed88235",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = \"YOUR-CATALOG\" # Change this to your catalog\n",
    "SCHEMA  = \"YOUR-SCHEMA\" # Change this to your schema name\n",
    "SOURCE_TABLE = \"forecast_daily_calendar_imperial_wbc_demo\"\n",
    "OUTPUT_TABLE = \"transformed_forecast_daily_calendar_imperial\"\n",
    "OUTPUT_TABLE_EXTERNAL_LOCATION = 's3://your-bucket-name/path/to/external/location/' # Change this to your external Databricks location\n",
    "\n",
    "# To find your external location's S3 path in Databricks:\n",
    "# 1. Navigate to the 'Data' explorer in your Databricks workspace.\n",
    "# 2. Select 'External Locations' from the left-hand menu.\n",
    "# 3. Click on the name of the external location you want to use.\n",
    "# 4. The 'URL' field on the details page contains the S3 path you need.\n",
    "\n",
    "SOURCE_TABLE_FQN = f\"`{CATALOG}`.`{SCHEMA}`.`{SOURCE_TABLE}`\"\n",
    "OUTPUT_TABLE_FQN = f\"`{CATALOG}`.`{SCHEMA}`.`{OUTPUT_TABLE}`\"\n",
    "\n",
    "print(\"Target UC input Delta table:\", SOURCE_TABLE_FQN)\n",
    "print(\"Target UC output Delta table:\", OUTPUT_TABLE_FQN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729261c-36c7-49ba-9a25-0b914010918b",
   "metadata": {},
   "source": [
    "### Confirm that you can read data from the Unity Catalog table in your Wherobots Notebook\n",
    "\n",
    "Read the table and confirm that it returns a dataframe with the Accuweather Data that returns a city with several days of forecast data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1fa26-ca81-4c51-a151-650933521254",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_smoke_test = sedona.read.table(SOURCE_TABLE_FQN)\n",
    "table_smoke_test.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f18b1-bf9c-481c-b653-ed5f1f02ab77",
   "metadata": {},
   "source": [
    "## Running spatial operations\n",
    "\n",
    "In this step, we will convert the latitude and longitude column into a `Point` object and add it to the table.\n",
    "\n",
    "This following transforms latitude and longitude data in a DataFrame into a spatially-aware geometry column and then validates the result.\n",
    "\n",
    "In short, it adds a new column named point by converting latitude and longitude values into a standard geographic point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a2ae9",
   "metadata": {},
   "source": [
    "## Proximity analysis: calculate distances to key locations\n",
    "In this section, you will perform a proximity analysis to calculate the distance from each weather forecast in your dataset to a specific point of interest. This allows you to filter data based on location and answer questions like, \"Which of these weather events is closest to my operations center?\"\n",
    "\n",
    "### A practical example\n",
    "Imagine your business has major operations or supply chain dependencies in the **Tokyo metropolitan area**, where severe weather can disrupt logistics and public safety. Your raw data contains thousands of forecasts across the region but lacks the context of which ones pose a direct threat to the city.\n",
    "\n",
    "By defining **Tokyo's coordinates**, you can calculate the distance from every weather event to the city center, saving the result in a new column like `distance_to_tokyo_meters`.\n",
    "\n",
    "With this new column, your data becomes an early-warning system. You can now easily ask critical business questions like:\n",
    "\n",
    "> \"Show me cities with **wind gusts over 40 mph** or **heavy precipitation** within a **500-kilometer radius** of Tokyo.\"\n",
    "\n",
    "This analysis turns your spatial data into actionable intelligence, allowing you to focus only on the events that directly impact your operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and Create Geometry\n",
    "# Read the table from Unity Catalog and create the necessary geometry column for spatial analysis.\n",
    "\n",
    "df = sedona.read.table(SOURCE_TABLE_FQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'point' geometry column from the latitude and longitude columns.\n",
    "\n",
    "df_w_geom = df.withColumn(\n",
    "    \"point\",\n",
    "    expr(\"ST_SetSRID(ST_MakePoint(longitude, latitude), 4326)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bca840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proximity Analysis: Calculate Distance to Tokyo\n",
    "# This is the core spatial operation. We calculate the distance from every weather\n",
    "# forecast point to our point of interest, Tokyo.\n",
    "\n",
    "# Define the point of interest (Tokyo) as a WKT string.\n",
    "\n",
    "tokyo_geom_wkt = \"POINT (139.6917 35.6895)\"\n",
    "\n",
    "# Wherobots efficiently calculates the spherical distance in meters for every row.\n",
    "df_with_distance = df_w_geom.withColumn(\n",
    "    \"distance_to_tokyo_meters\",\n",
    "    expr(f\"ST_DistanceSphere(point, ST_SetSRID(ST_GeomFromWKT('{tokyo_geom_wkt}'), 4326))\")\n",
    ")\n",
    "\n",
    "print(\"Calculated distance to Tokyo for each forecast.\")\n",
    "df_with_distance.select(\"distance_to_tokyo_meters\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1047fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for our alerts\n",
    "# 40 is the minimum wind speed that qualifies as a \"Severe Wind\" by the National Weather Service.\n",
    "# 2.0 inches of precipitation in a 24-hour period is considered \"Heavy Rain\" by the National Weather Service.\n",
    "# All measurements are in imperial units as provided by Accuweather.\n",
    "\n",
    "proximity_threshold_km = 500.0\n",
    "severe_wind_mph = 40\n",
    "heavy_precipitation_rate_inches = 0.30\n",
    "\n",
    "# Use a nested 'when' clause to build a descriptive alert string.\n",
    "df_with_threats = df_with_distance.withColumn(\n",
    "    \"threat_description\",\n",
    "    when(col(\"distance_to_tokyo_meters\") > proximity_threshold_km, lit(\"No Threat (Distance exceeds proximity threshold)\"))\n",
    "    .when(\n",
    "        (col(\"wind_gust_max\") >= severe_wind_mph) & (col(\"precipitation_lwe_max\") >= heavy_precipitation_rate_inches),\n",
    "        lit(\"High Wind & Flood Watch Near Tokyo\")\n",
    "    )\n",
    "    .when(col(\"wind_gust_max\") >= severe_wind_mph, lit(\"High Wind Warning Near Tokyo\"))\n",
    "    .when(col(\"precipitation_lwe_max\") >= heavy_precipitation_rate_inches, lit(\"Flood Watch Near Tokyo\"))\n",
    "    .otherwise(lit(\"Normal Conditions Near Tokyo\"))\n",
    ")\n",
    "\n",
    "print(\" Generated new 'threat_description' feature:\")\n",
    "df_with_threats.select(\"city_name\", \"wind_gust_max\", \"precipitation_lwe_max\", \"threat_description\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36580bf-2287-47cd-bd56-dc86a80be095",
   "metadata": {},
   "source": [
    "## Writing the results\n",
    "\n",
    "In this step we will write the results back to an external Delta table managed by Unity Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcfd3b1",
   "metadata": {},
   "source": [
    "### Data preparation for Databricks\n",
    "\n",
    "Before loading the data into Databricks, two preprocessing steps are performed on the geometry data:\n",
    "\n",
    "1. **Convert to WKT:** The geometry column is converted into its Well-Known Text (WKT) string representation.\n",
    "\n",
    "1. **Drop Original Column:** The 'point' column is dropped from the dataset because it contains the `geometry` datatype, `POINT`.\n",
    "\n",
    "This procedure is required because Databricks does not offer native support for columns containing geometry data types.\n",
    "\n",
    "> **Note:** A geometry data type is a special data type used in spatial databases to represent geographic features such as points (POINT), lines (LINESTRING), or polygons (POLYGON). You can learn more about them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df_with_threats.select(\n",
    "    col(\"city_name\"),\n",
    "    col(\"date\"),\n",
    "    col(\"temperature_avg\"),\n",
    "    col(\"wind_gust_max\"),\n",
    "    col(\"precipitation_lwe_max\"),\n",
    "    col(\"distance_to_tokyo_meters\"),\n",
    "    col(\"threat_description\") # This is our new, actionable feature with a feature type that is supported by Databricks!\n",
    ")\n",
    "\n",
    "print(\"\\nFinal schema to be written to Unity Catalog:\")\n",
    "final_df.printSchema()\n",
    "\n",
    "# Write the feature back to Unity Catalog\n",
    "\n",
    "final_df.createOrReplaceTempView(\"temp_final_df_view\")\n",
    "\n",
    "# Now, execute the SQL command to create the table from the temporary view.\n",
    "sedona.sql(f\"\"\"\n",
    "  CREATE OR REPLACE TABLE {OUTPUT_TABLE_FQN}\n",
    "  USING delta\n",
    "  LOCATION '{OUTPUT_TABLE_EXTERNAL_LOCATION}'\n",
    "  AS SELECT * FROM temp_final_df_view\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nSuccess! The feature has been written to an External Delta Table located at {OUTPUT_TABLE_FQN}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
