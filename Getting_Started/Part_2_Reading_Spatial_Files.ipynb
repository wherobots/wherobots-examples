{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292f99de-7bfb-4b29-a162-b53c3765a612",
   "metadata": {},
   "source": [
    "# **Introduction üåç**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5afcb-bb91-4aea-a699-4c696d5c7f24",
   "metadata": {},
   "source": [
    "Welcome to this notebook on **Efficient Loading of Raster and Vector Data in Wherobots**. This guide is designed for users working in a hosted notebook environment with preconfigured tools and libraries, making it easier to focus on geospatial workflows without needing extensive setup.\n",
    "\n",
    "### Objectives üéØ\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "1. üó∫Ô∏è Understand how to work with vector and raster data types in Wherobots.\n",
    "2. ‚òÅÔ∏è Learn how to load data from cloud storage and hosted environments.\n",
    "3. üìä Prepare to manage geospatial datasets efficiently in the Wherobots ecosystem.\n",
    "\n",
    "By the end of this tutorial, you will have foundational knowledge to load, query, and manage geospatial data in Wherobots using a combination of **Apache Sedona** and **WherobotsDB**.\n",
    "\n",
    "### What is Wherobots? ü§ñ\n",
    "\n",
    "Wherobots is a **cloud-native spatial analytics platform** designed for large-scale geospatial data processing. üöÄ It offers:\n",
    "\n",
    "- **WherobotsDB**: A scalable geospatial database based on Apache Iceberg, but for gerospatial.\n",
    "- **Apache Sedona Integration**: High-performance library geospatial queries and visualizations.\n",
    "- **Out-of-Database Raster Support**: Handle massive raster datasets efficiently.\n",
    "- **GeoParquet Support**: Work with optimized, open-source vector data formats.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Use a Hosted Environment? üñ•Ô∏è\n",
    "\n",
    "A hosted notebook environment in Wherobots provides:\n",
    "\n",
    "- **Preconfigured Libraries**: Tools like Apache Sedona and the WherobotsDB compute environment are ready to use.\n",
    "- **Managed Authentication**: Seamless connection to Wherobots Cloud without manual setup.\n",
    "- **Integrated Storage**: Access to both managed storage and external S3 buckets for geospatial data.\n",
    "- **Scalability**: Optimized runtimes for small-scale experimentation to large-scale production workflows.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts üìö\n",
    "\n",
    "#### Vector Data\n",
    "- Represents discrete features like points, lines, and polygons.\n",
    "- Common formats:\n",
    "  - **GeoParquet**: Optimized for modern geospatial workflows.\n",
    "  - **Shapefile**: Legacy format for geospatial data.\n",
    "  - **GeoJSON**: Lightweight and human-readable.\n",
    "\n",
    "#### Raster Data\n",
    "- Represents continuous phenomena using a grid of cells (e.g., elevation, satellite imagery).\n",
    "- Common formats:\n",
    "  - **Cloud-Optimized GeoTIFF (COG)**: Designed for efficient cloud storage and access.\n",
    "  - **NetCDF**: Often used for multidimensional climate data.\n",
    "\n",
    "#### GeoParquet\n",
    "GeoParquet is an open-source format designed for modern vector data workflows:\n",
    "\n",
    "- **Advantages**:\n",
    "  - Highly compact and optimized.\n",
    "  - Native support for spatial indexing.\n",
    "  - Compatibility with large-scale distributed processing frameworks.\n",
    "\n",
    "---\n",
    "\n",
    "In the following sections, we will:\n",
    "1. Set up our hosted environment.\n",
    "2. Load vector data into Wherobots.\n",
    "3. Load raster data into Wherobots.\n",
    "4. Write both vector and raster data back to GeoParquet and cloud storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99fb475-5731-4588-8a58-ba5a2c16c661",
   "metadata": {},
   "source": [
    "# **Section 2: Preconfigured Environment Setup üöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816d8d9-2c58-49a9-bd14-165d690534df",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "Before working with geospatial data in **Wherobots**, we need to initialize our **Sedona environment** and set up a **connection to S3 storage**. These steps ensure that our data processing workflows run efficiently within the **hosted notebook environment**.\n",
    "\n",
    "In this section, we will:\n",
    "1. **Initialize Apache Sedona** ‚Äì The geospatial engine that powers spatial operations in Spark.\n",
    "2. **Connect to S3 storage** ‚Äì The cloud storage system where our geospatial datasets are stored.\n",
    "\n",
    "---\n",
    "\n",
    "## **1Ô∏è‚É£ Initializing Apache Sedona**\n",
    "**Apache Sedona** is a spatial computing extension for **Apache Spark**. It allows us to efficiently load, transform, and analyze vector and raster data in **distributed computing environments**.\n",
    "\n",
    "### **üîπ Why do we need Sedona?**\n",
    "- Provides **Spatial SQL** capabilities (e.g., `ST_Intersects`, `ST_Within`).\n",
    "- Supports **vector** and **raster** data processing at scale.\n",
    "- Works seamlessly with **GeoParquet**, **GeoTIFF**, and other geospatial formats.\n",
    "\n",
    "### **üîπ Initializing Sedona in the Hosted Notebook**\n",
    "The following code initializes Sedona in our environment:\n",
    "\n",
    "```python\n",
    "# Import the Sedona library\n",
    "from sedona.spark import SedonaContext\n",
    "\n",
    "# Create the Sedona context (auto-configured for Wherobots)\n",
    "sedona = SedonaContext.builder().getOrCreate()\n",
    "```\n",
    "\n",
    "#### **üõ†Ô∏è What‚Äôs Happening?**\n",
    "- `SedonaContext.builder()` **automatically detects** the Spark environment.\n",
    "- `.getOrCreate()` **ensures only one instance** of Sedona is created.\n",
    "- This setup **enables spatial functions** within Spark SQL.\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Connecting to S3 Storage**\n",
    "Most geospatial datasets are **too large** to store locally, so we use **Amazon S3 (Simple Storage Service)** to manage and access spatial data efficiently.\n",
    "\n",
    "### **üîπ Why use S3 for geospatial data?**\n",
    "‚úÖ Stores **large-scale** vector and raster datasets.  \n",
    "‚úÖ Enables **cloud-based querying** without local downloads.  \n",
    "‚úÖ Supports **Out-of-Database (Out-DB) rasters** for efficient processing.\n",
    "\n",
    "### **üîπ Verifying the S3 Connection**\n",
    "Let‚Äôs test if we can **list files** in an S3 bucket:\n",
    "\n",
    "```python\n",
    "# Example: List files in an S3 bucket\n",
    "s3_files = sedona.spark.read.format(\"binaryFile\").load(\"s3a://wherobots-public-data/overturemaps/\")\n",
    "s3_files.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "üîç **This command helps us:**\n",
    "- Verify our connection to **Wherobots' public S3 bucket** for the data in this tutorial.\n",
    "- Confirm that we can access spatial datasets stored in the cloud.\n",
    "\n",
    "---\n",
    "\n",
    "## **‚úÖ Summary**\n",
    "- **Apache Sedona** is initialized to enable spatial computing in Spark.\n",
    "- **S3 Storage** is configured for reading **vector and raster** data from the cloud.\n",
    "- We verified the setup by **listing files** from an S3 bucket.\n",
    "\n",
    "With this setup, we are now ready to **load vector and raster data** into our notebook! üöÄüåç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf54316-ae4b-4f08-9c76-1e0f0e4fd1cc",
   "metadata": {},
   "source": [
    "# ‚å®Ô∏è **Section 2: Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0196ee-387b-41db-96e0-7f06f04c528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries and connect Apache Sedona to the Wherobots runtime\n",
    "from sedona.spark import SedonaContext\n",
    "\n",
    "config = SedonaContext.builder() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6e948-3b5d-4c86-92a8-bc44254f0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read out all the files we will be looking at in the tutorial \n",
    "\n",
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "s3_path = 's3a://wherobots-examples/data/onboarding_1/'\n",
    "\n",
    "try:\n",
    "    # List files in the S3 bucket (without loading full contents)\n",
    "    s3_files = sedona.read.format(\"binaryFile\").load(s3_path).select(input_file_name().alias(\"file_name\"))\n",
    "    # Show only file names\n",
    "    print(f\"Files in {s3_path}:\")\n",
    "    s3_files.show(truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error accessing S3 path: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6dd68-3be1-46eb-a753-b847579c6c27",
   "metadata": {},
   "source": [
    "# **Section 3: Loading Vector Data üó∫Ô∏è**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef237bea-8a4e-4152-8cc0-4a61a10eab55",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "**Vector data** represents real-world features using **points, lines, and polygons**. In Wherobots, we can load vector datasets from various formats, including **GeoParquet, GeoJSON, Shapefile, and CSV with geometry columns**.\n",
    "\n",
    "In this section, we will:\n",
    "1. **Understand vector data types and formats** in Wherobots.\n",
    "2. **Load vector datasets** from different sources like S3 and local storage.\n",
    "3. **Create a temporary view** to enable **SQL-based** spatial queries.\n",
    "\n",
    "---\n",
    "\n",
    "## **1Ô∏è‚É£ Understanding Vector Data Formats**\n",
    "Vector data is stored in multiple formats, each optimized for different use cases. Below are some common formats **supported in Wherobots**:\n",
    "\n",
    "| **Format**    | **Description** |\n",
    "|--------------|----------------|\n",
    "| **GeoParquet** üèóÔ∏è | A modern, efficient format for vector data that supports indexing and partitioning. |\n",
    "| **GeoJSON** üìú | A lightweight, human-readable format for spatial data on the web. |\n",
    "| **Shapefile** üìÇ | A legacy format widely used in GIS applications (requires multiple files). |\n",
    "| **CSV with Geometry** üìä | Tabular data containing WKT (Well-Known Text) geometries. |\n",
    "\n",
    "### **üõ†Ô∏è Why Use GeoParquet?**\n",
    "‚úÖ **Optimized for big data processing** (columnar format).  \n",
    "‚úÖ **Supports partitioning and indexing** (faster spatial queries).  \n",
    "‚úÖ **Seamless compatibility** with modern data lakes and cloud storage.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Loading Vector Data from S3**\n",
    "Wherobots provides **pre-configured access** to **public datasets** stored in **S3 buckets**. Let‚Äôs load a **GeoParquet** file from S3:\n",
    "\n",
    "```python\n",
    "# Load vector data from S3 (GeoParquet format)\n",
    "vector_df = sedona.read.format(\"geoparquet\").load(\"s3a://wherobots-public-data/overturemaps/theme=buildings/type=building\")\n",
    "\n",
    "# Print the schema to inspect the structure of the data\n",
    "vector_df.printSchema()\n",
    "\n",
    "# Display the first few rows of vector data\n",
    "vector_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "#### **üõ†Ô∏è What‚Äôs Happening?**\n",
    "- **`format(\"geoparquet\")`** ‚Üí Specifies that we are reading a **GeoParquet** file.\n",
    "- **`load(\"s3a://...\")`** ‚Üí Loads the dataset **directly from S3** without downloading it locally.\n",
    "- **`.printSchema()`** ‚Üí Displays the **columns** in our dataset.\n",
    "- **`.show(5, truncate=False)`** ‚Üí Displays the first **five rows** of vector data.\n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ Loading GeoJSON and Other Vector Formats**\n",
    "In addition to **GeoParquet**, we can load **GeoJSON, Shapefile, and CSV** vector datasets.\n",
    "\n",
    "### **üîπ Loading GeoJSON from Local Storage**\n",
    "GeoJSON is often used for **web-based mapping applications**.\n",
    "\n",
    "```python\n",
    "# Load a GeoJSON file from local managed storage\n",
    "geojson_df = sedona.read.format(\"json\").load(\"/data/shared/sample.geojson\")\n",
    "\n",
    "# Show first few rows\n",
    "geojson_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **üîπ Loading a Shapefile**\n",
    "Shapefiles consist of **multiple files** (`.shp`, `.dbf`, `.shx`), so we load **the directory containing them**.\n",
    "\n",
    "```python\n",
    "# Load a shapefile from local storage\n",
    "shapefile_df = sedona.read.format(\"shapefile\").load(\"/data/shared/shapefile_folder/\")\n",
    "\n",
    "# Show first few rows\n",
    "shapefile_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **üîπ Loading a CSV with a Geometry Column**\n",
    "CSV files can store **spatial data** using **WKT (Well-Known Text) geometries**.\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Load CSV data with a geometry column\n",
    "csv_df = sedona.read.format(\"csv\").option(\"header\", \"true\").load(\"/data/shared/sample.csv\")\n",
    "\n",
    "# Convert WKT column into a proper geometry column\n",
    "vector_df = csv_df.withColumn(\"geometry\", expr(\"ST_GeomFromWKT(geometry_column)\"))\n",
    "\n",
    "# Show first few rows\n",
    "vector_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "#### **üõ†Ô∏è What‚Äôs Happening?**\n",
    "- **`option(\"header\", \"true\")`** ‚Üí Ensures the first row is treated as column names.\n",
    "- **`ST_GeomFromWKT(geometry_column)`** ‚Üí Converts **WKT text** into a proper **geometry object**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4Ô∏è‚É£ Creating a Temporary SQL View**\n",
    "Once vector data is loaded, we **register it as a temporary view** so we can **query it using SQL**.\n",
    "\n",
    "```python\n",
    "# Register vector data as a temporary SQL view\n",
    "vector_df.createOrReplaceTempView(\"vector_data\")\n",
    "```\n",
    "\n",
    "### **üîπ Running a Spatial Query**\n",
    "We can now perform **SQL-based spatial analysis**:\n",
    "\n",
    "```sql\n",
    "-- Query all vector data where geometry intersects with a given polygon\n",
    "SELECT * FROM vector_data\n",
    "WHERE ST_Intersects(geometry, ST_GeomFromText('POLYGON((-122.5 37.5, -122.5 37.6, -122.4 37.6, -122.4 37.5, -122.5 37.5))'))\n",
    "```\n",
    "\n",
    "#### **üõ†Ô∏è What‚Äôs Happening?**\n",
    "- **`ST_Intersects(geometry, ST_GeomFromText(...))`** ‚Üí Checks if vector features **intersect** with a given **polygon**.\n",
    "- **This enables powerful spatial filtering** within large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## **‚úÖ Summary**\n",
    "- **Vector data** represents **points, lines, and polygons**.\n",
    "- We loaded vector datasets from **S3 and local storage** in formats like **GeoParquet, GeoJSON, Shapefile, and CSV**.\n",
    "- We **converted WKT strings** into proper geometries for spatial queries.\n",
    "- Finally, we **registered our data as a SQL view** and ran **a spatial query**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad1883-805b-41fd-9a4e-8e8829b521e0",
   "metadata": {},
   "source": [
    "# ‚å®Ô∏è **Section 3: Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2defe704-f950-4e56-8e88-086bd711c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parquet_path = 's3://wherobots-examples/data/onboarding_1/nyc_buildings.parquet'\n",
    "\n",
    "# Load GeoParquet data into a Spark DataFrame\n",
    "vector_df = sedona.read.format(\"geoparquet\").load(geo_parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e70dc7-a06a-4a3e-bf26-ef666c3dcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b85d85-3ba8-4d04-8fbc-75071c2db881",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5800896-f2f4-4e94-823c-b4930e7512c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the local path for GeoJSON data\n",
    "geojson_path = \"s3://wherobots-examples/data/onboarding_2/nyc_neighborhoods.geojson\"\n",
    "\n",
    "# Load GeoJSON data into a Spark DataFrame\n",
    "print(\"Loading GeoJSON data...\")\n",
    "geojson_df = sedona.read.format(\"geojson\").load(geojson_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e8179-ebfc-42cc-a7a6-a29fb944a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95efb6ac-afba-4e2d-afac-686d98cb73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f \n",
    "\n",
    "geojson_df = sedona.read.format(\"geojson\") \\\n",
    "    .load(geojson_path) \\\n",
    "    .withColumn(\"borough\", f.expr(\"properties['borough']\")) \\\n",
    "    .withColumn(\"boroughCode\", f.expr(\"properties['boroughCode']\")) \\\n",
    "    .withColumn(\"neighborhood\", f.expr(\"properties['neighborhood']\")) \\\n",
    "    .drop(\"_corrupt_record\") \\\n",
    "    .drop(\"properties\") \\\n",
    "    .drop(\"type\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac42ba-20c0-488b-96bf-ffa8fda51b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cb46c-af6d-4ade-8eb6-70e431c6cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting Lat/Long decimals in CSV data to geometry column...\")\n",
    "csv_path = \"s3://wherobots-examples/data/onboarding_2/311_Service_Requests_from_2010_to_Present_20240912.csv\"\n",
    "csv_df = sedona.read.format(\"csv\").option(\"header\", \"true\").load(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ab448-7180-4e03-ba44-214c3cfdb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fef6b6-ece0-4bb5-84e3-d6472a79260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = sedona.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(csv_path) \\\n",
    "    .withColumn(\"geometry\", f.expr(\"ST_MakePoint(Longitude, Latitude, 4326)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865fc37-a52d-45a8-b490-ab38846d7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df.createOrReplaceTempView('csv_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4464bf7-e154-4512-9d40-9324d57817d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Filter points within a polygon\n",
    "polygon_wkt = \"POLYGON((-73.9945201121 40.7512166031, -73.9925054739 40.7512166031, -73.9925054739 40.7498572827, -73.9945201121 40.7498572827, -73.9945201121 40.7512166031))\"\n",
    "query = f\"\"\"\n",
    "SELECT * FROM csv_df\n",
    "WHERE ST_Intersects(geometry, ST_GeomFromText('{polygon_wkt}'))\n",
    "\"\"\"\n",
    "filtered_df = sedona.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd01936-2a6c-47b6-a5da-ef028e99cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Show results\n",
    "print(f\"Number of filtered points within polygon: {filtered_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2301d-eb1b-49d4-82c8-1d68a5e7d315",
   "metadata": {},
   "source": [
    "# **Section 4: Loading Raster Data üõ∞Ô∏è**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ef3aa-dac6-4d71-a7d1-446acbfb3d8b",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "Raster data represents **continuous spatial information** such as:\n",
    "- Satellite imagery üõ∞Ô∏è\n",
    "- Elevation models ‚õ∞Ô∏è\n",
    "- Climate data üå¶Ô∏è\n",
    "\n",
    "Unlike vector data, which consists of **points, lines, and polygons**, raster data is stored as a **grid of pixels**, where each pixel represents a value (e.g., temperature, elevation).\n",
    "\n",
    "In this section, we will:\n",
    "1. **Understand raster data formats** supported in Wherobots.\n",
    "2. **Load raster datasets from S3 and local storage**.\n",
    "3. **Process raster data efficiently** using tiling and querying techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## **1Ô∏è‚É£ Understanding Raster Data Formats**\n",
    "Raster datasets come in various formats, optimized for different workflows.\n",
    "\n",
    "| **Format**    | **Description** |\n",
    "|--------------|----------------|\n",
    "| **GeoTIFF** üèûÔ∏è | A widely used raster format for geospatial imagery. |\n",
    "| **Cloud-Optimized GeoTIFF (COG)** ‚òÅÔ∏è | A version of GeoTIFF optimized for fast cloud access. |\n",
    "| **NetCDF** üåç | Commonly used for scientific climate and weather data. |\n",
    "| **JPEG2000** üñºÔ∏è | A compressed raster format with high quality. |\n",
    "| **HDF (Hierarchical Data Format)** üì¶ | Used for large datasets in Earth science. |\n",
    "\n",
    "### **üîπ Why Use Cloud-Optimized GeoTIFF (COG)?**\n",
    "‚úÖ **Faster access in cloud storage** (only reads necessary parts of the file).  \n",
    "‚úÖ **Optimized for parallel processing** in big data environments.  \n",
    "‚úÖ **Compatible with most GIS tools** like QGIS, GDAL, and Wherobots.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Loading Raster Data from S3**\n",
    "Now that we have **verified the available files**, we can **load a Cloud-Optimized GeoTIFF (COG) from S3**.\n",
    "\n",
    "```python\n",
    "# Load a Cloud-Optimized GeoTIFF (COG) from S3\n",
    "raster_df = sedona.read.format(\"raster\").load(\"s3a://wherobots-public-data/satellite_imagery/sample.tif\")\n",
    "\n",
    "# Print schema\n",
    "raster_df.printSchema()\n",
    "\n",
    "# Show raster metadata\n",
    "raster_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "### **üõ†Ô∏è What‚Äôs Happening?**\n",
    "- **`format(\"raster\")`** ‚Üí Loads the raw file **without reading** all pixel values.\n",
    "- **`RS_FromGeoTiff(content)`** ‚Üí Converts raster content into a **structured raster object**.\n",
    "- **`printSchema()`** ‚Üí Displays metadata about the raster dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ Loading Raster Data from Local Storage**\n",
    "If the raster dataset is stored in **local managed storage**, we can load it directly.\n",
    "\n",
    "```python\n",
    "# Load raster from local storage\n",
    "local_raster_df = sedona.read.format(\"raster\").load(\"/data/shared/sample.tif\")\n",
    "\n",
    "# Show raster metadata\n",
    "local_raster_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "### **üõ†Ô∏è What‚Äôs Happening?**\n",
    "- The **same method** is used as with S3, but the path is a local file (`/data/shared/...`).\n",
    "- The dataset is stored **within the Wherobots notebook environment**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4Ô∏è‚É£ Optimizing Raster Data with Tiling**\n",
    "Large raster files **must be tiled** to improve performance.\n",
    "\n",
    "```python\n",
    "# Explode raster into tiles\n",
    "tiled_raster_df = raster_df.selectExpr(\"RS_Explode(rast) as tiles\")\n",
    "\n",
    "# Create a SQL view for tiled rasters\n",
    "tiled_raster_df.createOrReplaceTempView(\"tiled_raster_df\")\n",
    "\n",
    "# Show some tiles\n",
    "tiled_raster_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "### **üõ†Ô∏è What‚Äôs Happening?**\n",
    "- **`RS_Explode(rast)`** ‚Üí Breaks the raster into **smaller, more manageable tiles**.\n",
    "- **Why?** ‚Üí Tiled rasters allow us to **query specific areas** without reading the entire dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## **5Ô∏è‚É£ Querying Raster Data**\n",
    "We can **extract pixel values** and perform **spatial queries** on raster datasets.\n",
    "\n",
    "### **Extracting Pixel Values at Specific Coordinates**\n",
    "```sql\n",
    "-- Query pixel value at a specific coordinate\n",
    "SELECT RS_PixelAsPoint(rast, 10, 15) AS pixel_point FROM raster_df;\n",
    "```\n",
    "üîπ Returns the **geographic coordinates** of a specific pixel.\n",
    "\n",
    "---\n",
    "\n",
    "### **Performing a Spatial Range Query**\n",
    "```sql\n",
    "-- Select rasters that intersect with a given polygon\n",
    "SELECT rast \n",
    "FROM raster_df \n",
    "WHERE RS_Intersects(rast, ST_GeomFromText('POLYGON((-122.5 37.5, -122.5 37.6, -122.4 37.6, -122.4 37.5, -122.5 37.5))'));\n",
    "```\n",
    "üîπ Returns only the **raster tiles** that intersect with the polygon.\n",
    "\n",
    "---\n",
    "\n",
    "## **‚úÖ Summary**\n",
    "- **Raster data** represents continuous geographic information.\n",
    "- We **listed available raster files** in an S3 bucket.\n",
    "- We **loaded Cloud-Optimized GeoTIFF (COG) files** into Wherobots.\n",
    "- We **converted raw files into structured raster objects**.\n",
    "- We **tiled raster data** for efficient querying.\n",
    "- We **ran spatial SQL queries** to extract pixel values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec3ef8-59af-4588-9d5e-5533da134913",
   "metadata": {},
   "source": [
    "# ‚å®Ô∏è **Section 4 Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d429c0d-7204-46eb-8c13-accc418d4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for a sample raster dataset\n",
    "raster_file = \"s3a://io-10m-annual-lulc/15T_2023.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea371f-af45-41fe-800c-aadb3a4080c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Cloud-Optimized GeoTIFF (COG) from S3\n",
    "raster_df = sedona.read.format(\"raster\").load(raster_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cebab-d678-43ab-b5c1-64a46cf6051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451126fc-b990-4854-b462-5b1c06f5e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_df.createOrReplaceTempView('raster_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a12fc1-a8c0-47c9-9624-4d2a2c50f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_df_tiled = raster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11615753-6b49-4168-8247-ad09ac06500f",
   "metadata": {},
   "source": [
    "Below is the **point location** we are querying against the **raster dataframe**:\n",
    "\n",
    "![Query Area](https://i.ibb.co/W4K0Lg90/Clean-Shot-2025-02-05-at-12-46-59-2x.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf4796-7665-44b1-965c-7ddeeea2ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying pixel value using SQL\n",
    "query = \"\"\"\n",
    "SELECT RS_Value(rast, \n",
    "    ST_Transform(\n",
    "        ST_SetSRID(\n",
    "            ST_Point(-93.367556, 44.231003), \n",
    "        4326),\n",
    "    'epsg:4326', 'epsg:32615')\n",
    ") AS pixel_point FROM raster_df \n",
    "\"\"\"\n",
    "\n",
    "result_df = sedona.sql(query)\n",
    "result_df.where(\"pixel_point is not null\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
