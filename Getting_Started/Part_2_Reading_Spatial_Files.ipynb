{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292f99de-7bfb-4b29-a162-b53c3765a612",
   "metadata": {},
   "source": [
    "![Wherobots logo](../assets/img/header-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5afcb-bb91-4aea-a699-4c696d5c7f24",
   "metadata": {},
   "source": [
    "# Reading spatial data\n",
    "\n",
    "Welcome to this notebook on loading of raster and vector efficiently. In this notebook, you will:\n",
    "\n",
    "1. Understand how to work with vector and raster data types in Wherobots.\n",
    "2. Learn how to load data from cloud storage and hosted environments.\n",
    "3. Prepare to manage geospatial datasets efficiently in the Wherobots ecosystem.\n",
    "\n",
    "![Map pointer on satellite image of crop fields](assets/img/part2_preview.jpg)\n",
    "\n",
    "**Vector data** represents discrete features like points, lines, and polygons. Common formats include:\n",
    "  - GeoParquet: Open source format that is optimized for modern, very large geospatial workflows.\n",
    "  - Shapefile: Legacy format for geospatial data.\n",
    "  - GeoJSON: Lightweight and human-readable.\n",
    "  - CSV: Tabular data that can contain geometries serialized in a WKT (well-known text) column or point coordinates as multiple columns.\n",
    "\n",
    "**Raster data** represents continuous phenomena using a grid of cells (e.g., elevation, satellite imagery). Common formats include:\n",
    "  - Cloud-Optimized GeoTIFF (COG): Designed for efficient cloud storage and access.\n",
    "  - NetCDF: Often used for multidimensional climate data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816d8d9-2c58-49a9-bd14-165d690534df",
   "metadata": {},
   "source": [
    "# Connect to data stored in Amazon S3\n",
    "\n",
    "Most geospatial datasets are too large to store locally, so we use Amazon S3 to manage and access spatial data. Wherobots queries run on cloud-based data and support **out-of-database (\"Out-DB\") rasters**, meaning it only reads the parts of rasters needed to process queries.\n",
    "\n",
    "Let’s test if we can list files in an S3 bucket. We will verify our connection to Wherobots's public S3 bucket for the data in this tutorial and confirm that we can access spatial datasets stored in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0196ee-387b-41db-96e0-7f06f04c528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import SedonaContext\n",
    "from pyspark.sql import functions as f \n",
    "\n",
    "# Initialize the Wherobots Sedona context\n",
    "config = SedonaContext.builder().getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6e948-3b5d-4c86-92a8-bc44254f0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the files we will be looking at in this notebook \n",
    "\n",
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "s3_path = 's3a://wherobots-examples/data/onboarding_1/'\n",
    "\n",
    "try:\n",
    "    # List files in the S3 bucket (without loading full contents)\n",
    "    s3_files = sedona.read.format(\"binaryFile\").load(s3_path).select(input_file_name().alias(\"file_name\"))\n",
    "    # Show only file names\n",
    "    print(f\"Files in {s3_path}:\")\n",
    "    s3_files.show(truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error accessing S3 path: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef237bea-8a4e-4152-8cc0-4a61a10eab55",
   "metadata": {},
   "source": [
    "# Loading vector data\n",
    "\n",
    "The next few cells show examples of how to load:\n",
    "\n",
    "- GeoParquet from an S3 bucket\n",
    "- GeoJSON from the notebook's local file storage\n",
    "- Shapefile\n",
    "- A CSV file with latitude and longitude stored in two columns\n",
    "\n",
    "In all these examples, we are loading the data into an Apache Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2defe704-f950-4e56-8e88-086bd711c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoParquet\n",
    "\n",
    "geo_parquet_path = 's3://wherobots-examples/data/onboarding_1/nyc_buildings.parquet'\n",
    "\n",
    "# Load GeoParquet data into a Spark DataFrame\n",
    "vector_df = sedona.read.format(\"geoparquet\").load(geo_parquet_path)\n",
    "vector_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5800896-f2f4-4e94-823c-b4930e7512c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoJSON\n",
    "\n",
    "geojson_path = \"s3://wherobots-examples/data/onboarding_2/nyc_neighborhoods.geojson\"\n",
    "\n",
    "geojson_df = sedona.read.format(\"geojson\").load(geojson_path)\n",
    "geojson_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3b0aa-bb5d-4414-98e6-baafea6ebce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make top-level columns from the properties subtree and drop unneeded columns\n",
    "geojson_df = geojson_df \\\n",
    "    .withColumn(\"borough\", f.expr(\"properties['borough']\")) \\\n",
    "    .withColumn(\"boroughCode\", f.expr(\"properties['boroughCode']\")) \\\n",
    "    .withColumn(\"neighborhood\", f.expr(\"properties['neighborhood']\")) \\\n",
    "    .drop(\"_corrupt_record\") \\\n",
    "    .drop(\"properties\") \\\n",
    "    .drop(\"type\") \n",
    "\n",
    "geojson_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cb46c-af6d-4ade-8eb6-70e431c6cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "\n",
    "csv_path = \"s3://wherobots-examples/data/onboarding_2/311_Service_Requests_from_2010_to_Present_20240912.csv\"\n",
    "csv_df = sedona.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(csv_path) \\\n",
    "    .withColumn(\"geometry\", f.expr(\"ST_MakePoint(Longitude, Latitude, 4326)\")) \\\n",
    "    .drop(\"Longitude\") \\\n",
    "    .drop(\"Latitude\")\n",
    "\n",
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af4716-3d64-423b-8f63-b8c0e95fd648",
   "metadata": {},
   "source": [
    "Let's break those calls down.\n",
    "\n",
    "**GeoParquet**: The Wherobots [Spatial Catalog](https://cloud.wherobots.com/spatial-catalog) hosts datasets stored in S3 buckets. \n",
    "\n",
    "- `format(\"geoparquet\")` → Specifies that we are reading a GeoParquet file.\n",
    "- `load(\"s3a://...\")` → Loads the dataset directly from S3 without downloading it locally.\n",
    "\n",
    "**GeoJSON** is often used for web-based mapping applications. GeoJSON data is often hierarchical, so it's often useful to pull those fields from inside a struct and make them columns of their own.\n",
    "\n",
    "**Shapefiles** consist of multiple files (`.shp`, `.dbf`, `.shx`), so we load the directory containing them.\n",
    "\n",
    "**CSV** cannot store binary fields like geometries, so spatial data often needs to be converted so we can use WherobotsDB's spatial query functions.\n",
    "\n",
    "- `option(\"header\", \"true\")` → Reads the first line as column names.\n",
    "- `ST_MakePoint()` → Converts decimal coordinates from columns into a geometry object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ef3aa-dac6-4d71-a7d1-446acbfb3d8b",
   "metadata": {},
   "source": [
    "# Loading raster data\n",
    "\n",
    "Raster data represents continuous spatial information such as pixels in satellite imagery, heights in elevation models, or temperate in climate or weather data. These values are stored as a grid of values and come in a variety formats.\n",
    "\n",
    "| Format    | Description |\n",
    "|--------------|----------------|\n",
    "| GeoTIFF | A widely used raster format for geospatial imagery |\n",
    "| Cloud-Optimized GeoTIFF (COG) | A version of GeoTIFF optimized for fast cloud access |\n",
    "| NetCDF | Commonly used for scientific climate and weather data |\n",
    "| JPEG2000 | A compressed raster format with high quality |\n",
    "| HDF (Hierarchical Data Format) | Used for large datasets in Earth science |\n",
    "\n",
    "For this notebook, we will focus on the COG format because it provides:\n",
    "\n",
    "- Faster access in cloud storage by reading only necessary parts of the file\n",
    "- Good parallel processing for large-scale data environments\n",
    "- Broad compatibility with GIS tools, including Wherobots\n",
    "\n",
    "```python\n",
    "# Load a Cloud-Optimized GeoTIFF (COG) from S3\n",
    "raster_df = sedona.read.format(\"raster\").load(\"s3a://wherobots-public-data/satellite_imagery/sample.tif\")\n",
    "```\n",
    "\n",
    "## Tips for using raster data\n",
    "\n",
    "**Optimizing with tiling**: Breaking large raster files into tiles can improve query performance. `RS_TileExplode` and `RS_Tile` are two Wherobots functions to create tiles as database records or arrays. [Docs: Raster functions](https://docs.wherobots.com/latest/references/wherobotsdb/raster-data/Raster-operators/?h=rs_tileexplode#raster-tiles)\n",
    "\n",
    "```python\n",
    "# Explode raster into tiles\n",
    "tiled_raster_df = raster_df.selectExpr(\"RS_TileExplode(rast) as tiles\")\n",
    "```\n",
    "\n",
    "**Querying raster values and rasters**: We can extract pixel values and perform spatial queries on raster datasets.\n",
    "\n",
    "```sql\n",
    "-- Query pixel value at a specific coordinate\n",
    "SELECT RS_PixelAsPoint(rast, 10, 15) AS pixel_point FROM raster_df;\n",
    "\n",
    "-- Select rasters that intersect with a given polygon\n",
    "SELECT rast \n",
    "FROM raster_df \n",
    "WHERE RS_Intersects(rast, ST_GeomFromText('POLYGON((-122.5 37.5, -122.5 37.6, -122.4 37.6, -122.4 37.5, -122.5 37.5))'));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d429c0d-7204-46eb-8c13-accc418d4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raster\n",
    "raster_file = \"s3a://io-10m-annual-lulc/15T_2023.tif\"\n",
    "raster_df = sedona.read.format(\"raster\").load(raster_file)\n",
    "raster_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11615753-6b49-4168-8247-ad09ac06500f",
   "metadata": {},
   "source": [
    "Below is the point location near Warsaw, Minnesota, USA we are querying against the raster dataframe.\n",
    "\n",
    "![Query Area](assets/img/part2_preview.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf4796-7665-44b1-965c-7ddeeea2ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view to enable SQL query\n",
    "raster_df.createOrReplaceTempView('raster_df')\n",
    "\n",
    "# Get the pixel value\n",
    "query = \"\"\"\n",
    "SELECT RS_Value(rast, \n",
    "    ST_Transform(\n",
    "        ST_SetSRID(\n",
    "            ST_Point(-93.367556, 44.231003), \n",
    "        4326),\n",
    "    'epsg:4326', 'epsg:32615')\n",
    ") \n",
    "AS pixel_point \n",
    "FROM raster_df \n",
    "WHERE RS_Intersects(rast, ST_Point(-93.367556, 44.231003))\n",
    "\"\"\"\n",
    "\n",
    "result_df = sedona.sql(query)\n",
    "result_df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
