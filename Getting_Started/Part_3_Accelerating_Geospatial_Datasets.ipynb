{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8903f713-76d1-4113-bb78-54758c942db4",
   "metadata": {},
   "source": [
    "![Wherobots logo](../assets/img/header-logo.png)\n",
    "\n",
    "# Accelerating Geospatial Datasets\n",
    "\n",
    "This notebook will show you how to optimize the way you work with large geospatial datasets — using Wherobots to efficiently manage, cluster, and export spatial data for high-performance analysis and downstream use.\n",
    "\n",
    "## What you will learn\n",
    "\n",
    "This notebook will teach you to:\n",
    "\n",
    "* Write DataFrames as managed tables in WherobotsDB\n",
    "* Apply spatial clustering to improve query performance on large datasets\n",
    "* Export geospatial tables to Geoparquet for sharing or external processing\n",
    "* Confirm export success and inspect output\n",
    "* Use both Python and SQL workflows for data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777dc09-52b7-4db1-8a8f-9a84d98d5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import SedonaContext\n",
    "\n",
    "config = SedonaContext.builder() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025410b",
   "metadata": {},
   "source": [
    "# Working with tabular data in Wherobots\n",
    "\n",
    "Wherobots supports loading structured tabular data directly from cloud storage. In this example, we are working with the GDELT dataset — a global event database published as daily CSV files on AWS S3.\n",
    "\n",
    "When working with your own data, you can:\n",
    "\n",
    "* Load data into Wherobots Cloud managed storage ([Docs](https://docs.wherobots.com/latest/develop/storage-management/managed-storage/?h=managed+st))\n",
    "* Connect directly to cloud storage like AWS S3 ([Docs](https://docs.wherobots.com/latest/develop/storage-management/s3-storage-integration/?h=s3))\n",
    "\n",
    "We’ll start by reading the GDELT data in its raw CSV format into a Sedona DataFrame.\n",
    "\n",
    "The GDELT dataset uses tab-separated values (TSV), so we specify the tab character (\\t) as the delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef09e5f-d74b-46f8-a00a-c8fbec2da4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 's3://gdelt-open-data/events/*.*.csv'\n",
    "\n",
    "csv_df = sedona.read.format(\"csv\") \\\n",
    "    .option(\"delimiter\", \"\\\\t\") \\\n",
    "    .load(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457253c-0dca-4da3-b6a9-1b66c0dd8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch the header file from the URL\n",
    "response = requests.get('https://gdeltproject.org/data/lookups/CSV.header.dailyupdates.txt')\n",
    "response.raise_for_status()  # ensure we notice bad responses\n",
    "\n",
    "# Assume the first line contains the header names and they're tab-delimited\n",
    "header_line = response.text.splitlines()[0].strip()\n",
    "headers = header_line.split('\\t')\n",
    "\n",
    "# Attach the headers\n",
    "csv_df = csv_df.toDF(*headers)\n",
    "\n",
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37aa8d7-f176-47b0-b004-dff7534bc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of rows\n",
    "csv_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9e3cf",
   "metadata": {},
   "source": [
    "## Creating a managed table from raw data\n",
    "\n",
    "We can now convert the DataFrame into an Iceberg table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c477e-3088-4c79-8472-605d1660f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view to create our table from the DataFrame\n",
    "csv_df.createOrReplaceTempView('csv_df')\n",
    "\n",
    "name = 'gdelt'\n",
    "\n",
    "# Create a Database\n",
    "sedona.sql(f'''\n",
    "CREATE DATABASE IF NOT EXISTS wherobots.{name}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090da2c8-b8b7-4f2f-9578-e4dc3dbf135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table and add a point geometry column\n",
    "sedona.sql(f'''\n",
    "CREATE OR REPLACE TABLE wherobots.{name}.gdelt AS \n",
    "SELECT *, \n",
    "ST_SetSRID(\n",
    "    ST_Point(ActionGeo_Long, ActionGeo_Lat),\n",
    "    4326\n",
    ") as geometry\n",
    "FROM csv_df\n",
    "LIMIT 10000\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee022067-438b-4cce-ba1b-716e4bccea83",
   "metadata": {},
   "source": [
    "Here's how we did it.\n",
    "\n",
    "- The `CREATE DATABASE` command creates the `wherobots.gdelt` database if it doesn’t already exist.\n",
    "- `CREATE OR REPLACE TABLE` makes a managed table by selecting data from the temporary view.\n",
    "- We also created a **geometry column** using the latitude and longitude fields from the CSV.\n",
    "  - We use `ST_Point` to create a point geometry from the latitude and longitude\n",
    "  - `ST_SetSRID` sets the spatial reference system to EPSG:4326 (WGS 84).\n",
    "- `LIMIT 10000` reduces the size of the data since this is a tutorial exercise and the typical GDELT daily data set has hundreds of millions of rows.\n",
    "  - Wherobots is built to scale to petabyte-sized, planetary spatial workloads. ([Docs: Runtimes](https://docs.wherobots.com/latest/develop/runtimes/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210d8e3",
   "metadata": {},
   "source": [
    "# Writing efficient GeoParquet with metadata\n",
    "\n",
    "When exporting spatial data for downstream use, the GeoParquet format offers an efficient, interoperable way to store vector data with embedded spatial metadata.\n",
    "\n",
    "> **GeoParquet** builds on the Parquet columnar format, adding metadata for geometries, coordinate reference systems (CRS), and bounding boxes. ([GeoParquet spec](https://geoparquet.org/))\n",
    "\n",
    "## Preparing the projection metadata\n",
    "\n",
    "GeoParquet requires metadata about the dataset’s coordinate reference system (CRS) in PROJJSON format. This ensures the geometry columns carry spatial context across different tools and workflows.\n",
    "\n",
    "In this example, we define the PROJJSON for EPSG:4326 (WGS 84), the most common global CRS. This JSON string describes the spatial reference system in a standard format compatible with GeoParquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df1634-c2c5-445a-b625-607f61617934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the JSON file for the 4326 projection for the GeoParquet metadata\n",
    "\n",
    "projjson = '''{\n",
    "    \"$schema\": \"https://proj.org/schemas/v0.7/projjson.schema.json\",\n",
    "    \"type\": \"GeographicCRS\",\n",
    "    \"name\": \"WGS 84\",\n",
    "    \"datum_ensemble\": {\n",
    "        \"name\": \"World Geodetic System 1984 ensemble\",\n",
    "        \"members\": [\n",
    "            {\n",
    "                \"name\": \"World Geodetic System 1984 (Transit)\",\n",
    "                \"id\": {\n",
    "                    \"authority\": \"EPSG\",\n",
    "                    \"code\": 1166\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"World Geodetic System 1984 (G730)\",\n",
    "                \"id\": {\n",
    "                    \"authority\": \"EPSG\",\n",
    "                    \"code\": 1152\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"World Geodetic System 1984 (G873)\",\n",
    "                \"id\": {\n",
    "                    \"authority\": \"EPSG\",\n",
    "                    \"code\": 1153\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"World Geodetic System 1984 (G1150)\",\n",
    "                \"id\": {\n",
    "                    \"authority\": \"EPSG\",\n",
    "                    \"code\": 1154\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"World Geodetic System 1984 (G1674)\",\n",
    "                \"id\": {\n",
    "                    \"authority\": \"EPSG\",\n",
    "                    \"code\": 1155\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"World Geodetic System 1984 (G1762)\",\n",
    "                \"id\": {\n",
    "                    \"authority\": \"EPSG\",\n",
    "                    \"code\": 1156\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"World Geodetic System 1984 (G2139)\",\n",
    "                \"id\": {\n",
    "                    \"authority\": \"EPSG\",\n",
    "                    \"code\": 1309\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"ellipsoid\": {\n",
    "            \"name\": \"WGS 84\",\n",
    "            \"semi_major_axis\": 6378137,\n",
    "            \"inverse_flattening\": 298.257223563\n",
    "        },\n",
    "        \"accuracy\": \"2.0\",\n",
    "        \"id\": {\n",
    "            \"authority\": \"EPSG\",\n",
    "            \"code\": 6326\n",
    "        }\n",
    "    },\n",
    "    \"coordinate_system\": {\n",
    "        \"subtype\": \"ellipsoidal\",\n",
    "        \"axis\": [\n",
    "            {\n",
    "                \"name\": \"Geodetic latitude\",\n",
    "                \"abbreviation\": \"Lat\",\n",
    "                \"direction\": \"north\",\n",
    "                \"unit\": \"degree\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Geodetic longitude\",\n",
    "                \"abbreviation\": \"Lon\",\n",
    "                \"direction\": \"east\",\n",
    "                \"unit\": \"degree\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"scope\": \"Horizontal component of 3D system.\",\n",
    "    \"area\": \"World.\",\n",
    "    \"bbox\": {\n",
    "        \"south_latitude\": -90,\n",
    "        \"west_longitude\": -180,\n",
    "        \"north_latitude\": 90,\n",
    "        \"east_longitude\": 180\n",
    "    },\n",
    "    \"id\": {\n",
    "        \"authority\": \"EPSG\",\n",
    "        \"code\": 4326\n",
    "    }\n",
    "}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6e5cc",
   "metadata": {},
   "source": [
    "## Partitioning and adding bounding boxes\n",
    "\n",
    "Before writing the data, we optimize it for efficient storage and querying:\n",
    "\n",
    "- GeoHash partitioning — We compute a GeoHash for each geometry and partition the data accordingly. This organizes the dataset spatially, improving query performance for spatial ranges.\n",
    "- Bounding box metadata — We add a bounding box for each geometry, allowing readers to perform fast spatial filtering without loading the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f5a4a-c3da-481d-8478-73ecc1c059e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the table by the GeoHash for improved partitioning\n",
    "\n",
    "gdelt = sedona.sql(f'''SELECT \n",
    "*,\n",
    "ST_GeoHash(geometry, 15) AS geohash,\n",
    "struct(st_xmin(geometry) as xmin, st_ymin(geometry) as ymin, st_xmax(geometry) as xmax, st_ymax(geometry) as ymax) as bbox\n",
    "FROM wherobots.{name}.gdelt''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ddf411",
   "metadata": {},
   "source": [
    "## Writing the GeoParquet file\n",
    "\n",
    "We write the data using the **GeoParquet** format with key options:\n",
    "\n",
    "* `geoparquet.version` — Specifies the format version (recommended: `1.1.0`)\n",
    "* `geoparquet.covering` — Defines the spatial covering method (we use `bbox`)\n",
    "* `geoparquet.crs` — Passes the PROJJSON metadata for the CRS\n",
    "* `compression` — We apply `snappy` compression for efficient storage\n",
    "\n",
    "The data is repartitioned by `geohash` and sorted within partitions to improve downstream query performance:\n",
    "\n",
    "> This writes a partitioned, metadata-rich GeoParquet dataset ready for scalable spatial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7cc5d-23b5-4359-84d1-bcba410da18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "user_uri = os.getenv(\"USER_S3_PATH\")\n",
    "\n",
    "gdelt.repartitionByRange(30, \"geohash\") \\\n",
    "    .sortWithinPartitions(\"geohash\") \\\n",
    "    .drop(\"geohash15\") \\\n",
    "    .write \\\n",
    "    .format(\"geoparquet\") \\\n",
    "    .option(\"geoparquet.version\", \"1.1.0\") \\\n",
    "    .option(\"geoparquet.covering\", \"bbox\") \\\n",
    "    .option(\"geoparquet.crs\", projjson) \\\n",
    "    .save(user_uri + \"gdelt-snappy\", mode='overwrite', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47d3e3-a773-491b-84f6-d949f2b85561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
