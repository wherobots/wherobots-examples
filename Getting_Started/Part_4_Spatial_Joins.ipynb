{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5ea0f4-2b47-480d-b20d-c3796c60d6ea",
   "metadata": {},
   "source": [
    "# Performing Spatial Joins in Wherobots\n",
    "\n",
    "This notebook will guide you through performing spatial joins in Wherobots using Python and the DataFrame API ‚Äî giving you a hands-on understanding of how to combine datasets based on their spatial relationships.\n",
    "\n",
    "## What you will learn\n",
    "\n",
    "This notebook will teach you to:\n",
    "\n",
    "* Perform **standard spatial joins** ‚Äî identifying features within other geometries\n",
    "* Execute **nearest neighbor joins** ‚Äî finding the closest feature between datasets\n",
    "* Calculate **zonal statistics** ‚Äî summarizing values within geographic zones\n",
    "* Apply optimization techniques like spatial partitioning with GeoHashes\n",
    "* Visualize join results using interactive tools\n",
    "\n",
    "> Spatial joins are a core operation in geospatial analysis, allowing you to merge datasets based on how their features relate in space.\n",
    "\n",
    "This notebook focuses on practical workflows and scalable processing with Wherobots and Apache Sedona.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a50783-0a1a-41b3-801b-80ac4efd01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import SedonaContext\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "config = SedonaContext.builder().getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f050d715-9bfc-4045-af91-71833b0db1ca",
   "metadata": {},
   "source": [
    "# üìÄ Load Spatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de243b07-516f-4e6d-bfa3-263785dc11b5",
   "metadata": {},
   "source": [
    "Now, we load two spatial datasets stored in Wherobots Managed Storage:\n",
    "- **Polygons:** Represent administrative boundaries.\n",
    "- **Points:** Represent facility locations.\n",
    "\n",
    "```python\n",
    "# Load the polygon dataset (administrative boundaries) using a Spatial SQL Query\n",
    "# Using sedona.sql, create a dataframe from the query\n",
    "query = '''\n",
    "SELECT \n",
    "    * \n",
    "FROM\n",
    "    wherobots_open_data.overture_maps_foundation.divisions_division_area\n",
    "WHERE\n",
    "    subtype = 'locality'\n",
    "    AND country = 'US'\n",
    "'''\n",
    "\n",
    "polygons_df = sedona.sql(query)\n",
    "# (Alternatively, load from a file with spark.read.format(\"geoparquet\") if necessary)\n",
    "\n",
    "# Load the points dataset (facilities)\n",
    "points_df = sedona.table(\"wherobots.sample_data.facilities\")\n",
    "# (Alternatively, load from a file with spark.read.format(\"geoparquet\"))\n",
    "\n",
    "# Display a sample of the polygon dataset\n",
    "print(\"üîπ Sample of the Polygon Dataset (Administrative Boundaries):\")\n",
    "polygons_df.show(5, truncate=False)\n",
    "\n",
    "# Display a sample of the points dataset\n",
    "print(\"üîπ Sample of the Points Dataset (Facilities):\")\n",
    "points_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "*Detailed Explanation:*  \n",
    "- We use the `sedona.table` function to load the data directly from the Wherobots catalog.\n",
    "- Two DataFrames are created: one for polygons and one for points.\n",
    "- We then display the first five rows of each dataset to verify the contents. This helps ensure our data is loaded correctly and gives a preview of the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405e557-f963-40bd-adf6-7e91bd7ce47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT \n",
    "    * \n",
    "FROM\n",
    "    wherobots_open_data.overture_maps_foundation.divisions_division_area\n",
    "WHERE\n",
    "    subtype = 'locality'\n",
    "    AND country = 'US'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8c5de-131e-4b6d-9e30-43c98e5b71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_df = sedona.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad4886-adf9-44c5-9133-e74feaf2d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df = sedona.table(\"wherobots_open_data.foursquare.places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd4c31-d612-4c9d-b3fe-b5f56c7a9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîπ Sample of the Polygon Dataset (Administrative Boundaries):\")\n",
    "polygons_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ccb2a-191b-45d6-843c-830bdd39b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîπ Sample of the Points Dataset (Facilities):\")\n",
    "points_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce45917-a5cf-40cf-b0aa-243c65034069",
   "metadata": {},
   "source": [
    "# ü§ùüèº Standard Spatial Join (Pythonic Approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c634e-7922-4a7f-8b24-0e5fffe1399c",
   "metadata": {},
   "source": [
    "In a standard spatial join, we want to link points (facilities) with the polygons (administrative boundaries) that contain them. We use spatial predicates like `ST_Intersects`.\n",
    "\n",
    "```python\n",
    "# Alias the DataFrames for clarity\n",
    "facilities = points_df.alias(\"f\")\n",
    "admin_boundaries = polygons_df.alias(\"poly\")\n",
    "\n",
    "# Perform a spatial join:\n",
    "# Join the facilities and admin_boundaries DataFrames where the facility geometry\n",
    "# intersects with the polygon geometry using the ST_Intersects predicate.\n",
    "spatial_join_df = facilities.join(\n",
    "    admin_boundaries,\n",
    "    expr(\"ST_Intersects(poly.geometry, f.geom)\")\n",
    ")\n",
    "\n",
    "# Show a few rows of the spatial join result\n",
    "print(\"üîπ Standard Spatial Join Results (Facilities within Administrative Boundaries):\")\n",
    "spatial_join_df.show(10, truncate=False)\n",
    "```\n",
    "\n",
    "*Detailed Explanation:*  \n",
    "- We alias the points and polygons DataFrames as \"f\" and \"poly\" for easier reference.\n",
    "- The join condition uses the `ST_Intersects` function, which returns `true` if a point lies within (or touches) a polygon.\n",
    "- The join operation returns combined rows from both DataFrames where the condition is met.\n",
    "- We display the first 10 rows to inspect the join result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a1e0e-b270-497e-9876-482a0c8e552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities = points_df.alias(\"f\")\n",
    "admin_boundaries = polygons_df.alias(\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f217c5-4186-4d24-b0ba-b2918d68be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_join_df = facilities.join(\n",
    "    admin_boundaries,\n",
    "    expr(\"ST_Intersects(poly.geometry, f.geom)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f8310-f0c2-48a7-bc8e-227ad50e2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spatial_join_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8374cc-6ac0-4490-a521-e9b91b482737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîπ Standard Spatial Join Results (Facilities within Administrative Boundaries):\")\n",
    "spatial_join_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc705d-3fbe-40e1-b4a2-7d59b7ad021b",
   "metadata": {},
   "source": [
    "# üî¢ Efficiently Counting Points Within Each Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd392cf-f46d-4262-b3d1-0f2318110f9f",
   "metadata": {},
   "source": [
    "In this step, we combine the spatial join and aggregation into one efficient operation. By directly applying the spatial predicate (`ST_Intersects`) during the join and then aggregating (grouping by polygon ID) to count the points, we allow Wherobots to optimize the query. This minimizes data shuffling and processing by filtering data at the source (e.g., using GeoParquet spatial filter pushdown). This method is particularly beneficial when working with large datasets.\n",
    "\n",
    "```python\n",
    "# Efficiently count the number of facilities (points) that fall inside each polygon.\n",
    "# This approach directly aggregates the data after filtering with the spatial predicate.\n",
    "points_count_efficient_df = polygons_df.alias(\"poly\") \\\n",
    "    .join(points_df.alias(\"f\"), expr(\"ST_Intersects(poly.geom, f.geom)\")) \\\n",
    "    .groupBy(\"poly.id\") \\\n",
    "    .agg(expr(\"COUNT(*) as point_count\"))\n",
    "\n",
    "# Display the aggregated result\n",
    "print(\"üîπ Efficient Count of Points in Each Polygon:\")\n",
    "points_count_efficient_df.show(10, truncate=False)\n",
    "```\n",
    "\n",
    "*Detailed Explanation:*  \n",
    "- **Spatial Predicate Pushdown:** By using `ST_Intersects` directly in the join condition, Wherobots can push the spatial predicate down to the data source level (especially if you're using spatially optimized formats such as GeoParquet). This means only the relevant data (points that are near or within the polygons) is loaded and processed. üöÄ  \n",
    "- **Single-step Aggregation:** We immediately group the joined result by the polygon's identifier (`poly.id`) and use the `COUNT(*)` aggregate function to determine how many points fall within each polygon. This avoids creating an intermediate, full join result before counting, which is both memory and compute efficient.  \n",
    "- **Performance Gains:** Combining filtering and aggregation reduces unnecessary data movement and computation, making the operation much more efficient on large datasets.\n",
    "\n",
    "This method is a best practice when dealing with spatial queries in environments like Wherobots that are optimized for spatial predicates. Enjoy the performance improvements and cleaner code! üòä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e923ef-c1a4-4723-b6bb-ed2e73eebe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_count_efficient_df = polygons_df.alias(\"poly\") \\\n",
    "    .join(points_df.alias(\"f\"), expr(\"ST_Intersects(poly.geometry, f.geom)\")) \\\n",
    "    .groupBy(\"poly.id\") \\\n",
    "    .agg(expr(\"COUNT(*) as point_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318d418-4c06-49f3-a525-c9abab13c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîπ Efficient Count of Points in Each Polygon:\")\n",
    "points_count_efficient_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fb8fa-944a-499c-bc8b-be085da1342f",
   "metadata": {},
   "source": [
    "# üèòÔ∏è Nearest Neighbor Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb62686-71a5-4367-9c6a-5aa4668e7116",
   "metadata": {},
   "source": [
    "The nearest neighbor join finds, for each facility, the closest centroid of an administrative area. This can be useful for determining the nearest center point or service area.\n",
    "\n",
    "```python\n",
    "# Compute centroids for each polygon to represent the center of each administrative area.\n",
    "centroids_df = polygons_df.selectExpr(\"id\", \"ST_Centroid(geom) as centroid\")\n",
    "\n",
    "# Display a few centroid records\n",
    "print(\"üîπ Centroids of Administrative Boundaries:\")\n",
    "centroids_df.show(5, truncate=False)\n",
    "```\n",
    "\n",
    "*Detailed Explanation:*  \n",
    "- We create a new DataFrame `centroids_df` by selecting the `id` and computing the centroid of each polygon using the `ST_Centroid` function.\n",
    "- These centroids will later serve as reference points for our nearest neighbor calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa91705-5f56-4bd9-9050-23ff86081d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_df = polygons_df.selectExpr(\"id\", \"ST_Centroid(geometry) as centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d31754-18db-46a8-8c0d-fe1c2998f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîπ Centroids of Administrative Boundaries:\")\n",
    "centroids_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada13f1f-a89e-405a-a2c3-56977720047a",
   "metadata": {},
   "source": [
    "In this approach, we use the ST_AKNN function to directly obtain the k nearest neighbors for each query geometry. The function signature is:  \n",
    "\n",
    "```\n",
    "ST_AKNN(query_geom, object_geom, k, include_ties)\n",
    "```\n",
    "\n",
    "In our example, we assume the following:  \n",
    "- **Queries DataFrame:** Our facilities DataFrame (`points_df`) represents the query geometries.  \n",
    "- **Objects DataFrame:** Our centroids DataFrame (`centroids_df`), which was created earlier by computing the centroid of each polygon, represents the object geometries.\n",
    "\n",
    "The SQL equivalent of our operation is:  \n",
    "\n",
    "```\n",
    "SELECT\n",
    "    QUERIES.ID AS QUERY_ID,\n",
    "    QUERIES.GEOMETRY AS QUERIES_GEOM,\n",
    "    OBJECTS.GEOMETRY AS OBJECTS_GEOM\n",
    "FROM QUERIES JOIN OBJECTS ON ST_AKNN(QUERIES.GEOMETRY, OBJECTS.GEOMETRY, 4, FALSE)\n",
    "```\n",
    "\n",
    "Below is the Pythonic implementation:\n",
    "\n",
    "```python\n",
    "# Use ST_AKNN to perform an approximate k-nearest neighbor join between the queries and objects.\n",
    "# In our example, we join the facilities (points_df) with the centroids (centroids_df),\n",
    "# returning the four nearest centroids for each facility. The \"false\" parameter indicates that ties are not included.\n",
    "aknn_df = points_df.alias(\"q\").join(\n",
    "    centroids_df.alias(\"o\"),\n",
    "    expr(\"ST_AKNN(q.geom, o.centroid, 4, false)\")\n",
    ")\n",
    "\n",
    "# Select and rename the columns for clarity.\n",
    "# Here, we select the query's id and geometry as well as the object's geometry.\n",
    "aknn_result_df = aknn_df.select(\n",
    "    expr(\"q.id as query_id\"),\n",
    "    expr(\"q.geom as query_geom\"),\n",
    "    expr(\"o.centroid as object_geom\")\n",
    ")\n",
    "\n",
    "# Display the result of the nearest neighbor join using ST_AKNN.\n",
    "print(\"üîπ Nearest Neighbor Join using ST_AKNN:\")\n",
    "aknn_result_df.show(10, truncate=False)\n",
    "```\n",
    "\n",
    "**Detailed Markdown Explanation:**  \n",
    "- **Purpose:**  \n",
    "  This code uses the `ST_AKNN` function to efficiently find the four closest (k = 4) object geometries (in this case, centroids) for each query geometry (facilities). This method is optimized within Wherobots and leverages the spatial predicate pushdown capabilities of the compute engine.\n",
    "  \n",
    "- **Process:**  \n",
    "  1. **Aliasing:**  \n",
    "     We alias `points_df` as `\"q\"` (representing the queries) and `centroids_df` as `\"o\"` (representing the objects) for easier reference.  \n",
    "  2. **Joining with ST_AKNN:**  \n",
    "     The join condition `expr(\"ST_AKNN(q.geom, o.centroid, 4, false)\")` applies the ST_AKNN function to determine whether a given object is among the four nearest neighbors of a query geometry.  \n",
    "  3. **Column Selection:**  \n",
    "     After joining, we select and rename columns to clearly indicate the query ID, the query geometry, and the object geometry (centroid) for each match.  \n",
    "  4. **Display:**  \n",
    "     Finally, we display the top 10 results. This gives you a clear view of which centroids are among the nearest neighbors for each facility.\n",
    "\n",
    "- **Efficiency:**  \n",
    "  By using `ST_AKNN`, the engine performs an optimized nearest neighbor search without the need for an expensive cross join or manual windowing. This is especially beneficial when working with large datasets where performance is critical.\n",
    "\n",
    "This approach provides a clean, efficient, and Pythonic solution for nearest neighbor joins using Wherobots and Apache Sedona. Enjoy the streamlined spatial analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49740576-8005-47e0-86c9-796ef8ab4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aknn_df = points_df.alias(\"q\").join(\n",
    "    centroids_df.alias(\"o\"),\n",
    "    expr(\"ST_AKNN(q.geom, o.centroid, 4, false)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a93fd-c68e-4372-9ee6-fbf14fe5f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aknn_result_df = aknn_df.select(\n",
    "    expr(\"q.fsq_place_id as query_id\"),\n",
    "    expr(\"q.geom as query_geom\"),\n",
    "    expr(\"o.centroid as object_geom\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b86cb5-fc43-4f3c-b70e-e146e65550b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîπ Nearest Neighbor Join using ST_AKNN:\")\n",
    "aknn_result_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4a1ff-148a-40b7-bf4e-d980f2c0fefd",
   "metadata": {},
   "source": [
    "# ü¶æ Advanced Optimization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe90ea-f341-4dff-b12e-7c1cba73bc7c",
   "metadata": {},
   "source": [
    "Optimizing spatial operations is critical for performance, especially with large datasets. One common strategy is to repartition the data using a spatial key, such as a geohash. This improves data locality and reduces shuffle during joins.\n",
    "\n",
    "## Cluster Data Using Geohash\n",
    "\n",
    "```python\n",
    "# Add a geohash column to the facilities and polygons DataFrames with a precision level of 5.\n",
    "points_df = points_df.withColumn(\"geohash\", expr(\"ST_GeoHash(geom, 5)\"))\n",
    "polygons_df = polygons_df.withColumn(\"geohash\", expr(\"ST_GeoHash(geom, 5)\"))\n",
    "\n",
    "# Repartition the DataFrames based on the geohash column to group nearby features together.\n",
    "points_df = points_df.withColumn(\"geohash\", expr(\"ST_GeoHash(geometry, 6)\"))\n",
    "polygons_df = polygons_df.withColumn(\"geohash\", expr(\"ST_GeoHash(geometry, 6)\"))\n",
    "\n",
    "sorted_points = points_df.sort(col(\"geohash\"))\\\n",
    "    .drop(\"geohash\")\n",
    "\n",
    "sorted_polys = polygons_df.sort(col(\"geohash\"))\\\n",
    "    .drop(\"geohash\")\n",
    "\n",
    "print(\"üîπ DataFrames clustered by geohash for improved spatial join performance!\")\n",
    "```\n",
    "\n",
    "*Detailed Explanation:*  \n",
    "- The `ST_GeoHash` function converts each geometry into a geohash string. The precision parameter (here, 5) determines the spatial resolution.\n",
    "- Clustering by geohash ensures that spatially proximate features are processed in the same partition, which can significantly speed up join operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f584252-4e2d-4cb0-b038-03a0082dbb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spatial_join_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43877613-167b-4d20-a381-4ee6fb9c7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'joins'\n",
    "sedona.sql(f\"CREATE DATABASE IF NOT EXISTS wherobots.{database_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffd712-ddd8-4795-86f0-bcd76849d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df = points_df.withColumn(\"geohash\", expr(\"ST_GeoHash(geom, 6)\"))\n",
    "polygons_df = polygons_df.withColumn(\"geohash\", expr(\"ST_GeoHash(geometry, 6)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be839dc6-3904-4f8b-9e69-545363bbc184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce495c7-1ad6-43ae-a9c1-1f60a0e52b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_points = points_df.sort(col(\"geohash\"))\\\n",
    "    .drop(\"geohash\")\n",
    "\n",
    "sorted_polys = polygons_df.sort(col(\"geohash\"))\\\n",
    "    .drop(\"geohash\")\n",
    "\n",
    "sorted_points.writeTo(f\"wherobots.{database_name}.points\").createOrReplace()\n",
    "sorted_polys.writeTo(f\"wherobots.{database_name}.polygons\").createOrReplace()\n",
    "\n",
    "print(\"üîπ DataFrames sorted by geohash for improved spatial join performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2474b-685d-428d-9e7f-a6bb781b4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias the DataFrames for clarity\n",
    "facilities = sedona.table(f\"wherobots.{database_name}.points\").alias(\"f\")\n",
    "admin_boundaries = sedona.table(f\"wherobots.{database_name}.polygons\").alias(\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221ffc5-0e8b-4cdb-b1a3-8fe20ebf4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_join_df_partition = facilities.join(\n",
    "    admin_boundaries,\n",
    "    expr(\"ST_Intersects(poly.geometry, f.geom)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda8f45-62aa-4097-90b0-9515a0c786e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spatial_join_df_partition.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3467ca88-f2b6-477d-8587-122894ba3c93",
   "metadata": {},
   "source": [
    "# üíÖüèº Visualizing Spatial Join Results with SedonaKepler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca759b-fcb6-46b4-9a41-00b170fffc9b",
   "metadata": {},
   "source": [
    "Wherobots offers interactive visualization tools to help you explore your spatial data. We will use SedonaKepler and SedonaPyDeck to visualize our spatial join and zonal statistics results.\n",
    "\n",
    "### 7.1 Visualizing Spatial Join Results with SedonaKepler\n",
    "\n",
    "```python\n",
    "# Import SedonaKepler for interactive mapping\n",
    "from sedona.visualize import SedonaKepler\n",
    "\n",
    "# Create an interactive map from the spatial join DataFrame.\n",
    "# The map will show facilities along with the administrative boundaries they fall within.\n",
    "kepler_map = SedonaKepler.create_map(df=spatial_join_df, name=\"Facilities_Within_Zones\")\n",
    "\n",
    "# Display the interactive map in your Jupyter Notebook\n",
    "kepler_map.show()\n",
    "```\n",
    "\n",
    "*Detailed Explanation:*  \n",
    "- SedonaKepler integrates with KeplerGl to provide interactive spatial visualizations.\n",
    "- The `create_map` function takes the spatial join DataFrame and renders an interactive map.\n",
    "- This is especially useful for exploring the spatial relationships between facilities and boundaries visually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c4e70-1b0b-4a10-aa5f-5d20a4836174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the WKT polygon as a string\n",
    "wkt_polygon = \"POLYGON((-84.656729 33.983118, -84.109483 33.983118, -84.109483 33.562116, -84.656729 33.562116, -84.656729 33.983118))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1985a0b-7d24-4661-a5cc-ed739ae9b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_facilities_df = spatial_join_df.select(\n",
    "    \"f.fsq_place_id\",    # Unique facility identifier\n",
    "    \"f.name\",            # Facility name\n",
    "    \"f.address\",         # Facility address\n",
    "    \"f.locality\",        # Locality information\n",
    "    \"f.region\",          # Region name\n",
    "    \"f.postcode\",        # Postal code\n",
    "    \"f.admin_region\",    # Administrative region\n",
    "    \"f.post_town\",       # Post town\n",
    "    \"f.country\",         # Country name\n",
    "    \"f.geom\",            # Facility geometry\n",
    "    \"poly.names\"         # Additional name information\n",
    ").filter(\n",
    "    expr(f\"ST_Intersects(geometry, ST_GeomFromText('{wkt_polygon}'))\")\n",
    ").selectExpr(\"*\", \"names.primary\") \\\n",
    ".drop(\"names\")\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(\"üîπ Detailed Facility Information from spatial_join_df:\")\n",
    "detailed_facilities_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f7520-deb2-46dc-af9e-1302de10638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "\n",
    "# Create an interactive map from the spatial join DataFrame.\n",
    "# The map will show facilities along with the administrative boundaries they fall within.\n",
    "kepler_map = SedonaKepler.create_map(df=detailed_facilities_df, name=\"Facilities_Within_Zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b387254-f978-4dfd-a2da-26a462f32753",
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d182e783-5b15-4304-ac9a-af95e9904496",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è Creating a Choropleth Map for Point in Polygon Join with SedonaPyDeck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106427c7-e56c-40db-94f8-5f4a102a9076",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# Import SedonaPyDeck for creating choropleth maps\n",
    "from sedona.maps.SedonaPyDeck import SedonaPyDeck\n",
    "\n",
    "# Create a choropleth map using the zonal statistics DataFrame.\n",
    "# The zones are colored based on the 'avg_measurement' column, highlighting variations across regions.\n",
    "choropleth_map = SedonaPyDeck.create_choropleth_map(\n",
    "    df=zonal_stats_df,\n",
    "    plot_col=\"avg_measurement\"  # This column drives the color intensity\n",
    ")\n",
    "\n",
    "# Display the choropleth map in your Jupyter Notebook\n",
    "choropleth_map.show()\n",
    "```\n",
    "\n",
    "*Detailed Explanation:*  \n",
    "- SedonaPyDeck leverages the pydeck library to create visually appealing maps.\n",
    "- By passing the `zonal_stats_df` and specifying the `plot_col`, a choropleth map is created where the color intensity of each zone corresponds to its average measurement.\n",
    "- This helps to quickly identify areas with high or low average values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd61967-7bf4-45bb-9050-9f46b891d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_count_efficient_df = polygons_df.alias(\"poly\") \\\n",
    "    .filter(\n",
    "        expr(f\"ST_Intersects(geometry, ST_GeomFromText('{wkt_polygon}'))\")\n",
    "    ) \\\n",
    "    .join(points_df.alias(\"f\"), expr(\"ST_Intersects(poly.geometry, f.geom)\")) \\\n",
    "    .groupBy(\"poly.id\", \"poly.geometry\") \\\n",
    "    .agg(expr(\"COUNT(*) as point_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de5c81-19ad-48c9-946f-181453069962",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_count_efficient_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98e468-3b4e-4a19-8491-aba75cdf2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.maps.SedonaPyDeck import SedonaPyDeck\n",
    "\n",
    "# Create a choropleth map using the zonal statistics DataFrame.\n",
    "# The zones are colored based on the 'avg_measurement' column, highlighting variations across regions.\n",
    "\n",
    "choropleth_map = SedonaPyDeck.create_choropleth_map(\n",
    "    df=points_count_efficient_df,\n",
    "    plot_col=\"point_count\"  # This column drives the color intensity\n",
    ")\n",
    "\n",
    "# Display the choropleth map in your Jupyter Notebook\n",
    "choropleth_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff328c-003e-4b67-bddc-652a1dbcb187",
   "metadata": {},
   "source": [
    "# üéÅ Conclusion and Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407dfba6-8270-422e-bf0e-91802ceed10e",
   "metadata": {},
   "source": [
    "### Summary of Key Steps:\n",
    "- **Environment Setup:** We initialized Spark and Sedona for spatial processing.\n",
    "- **Data Loading:** We loaded two spatial datasets‚Äîadministrative boundaries (polygons) and facilities (points).\n",
    "- **Standard Spatial Join:** We performed a join using the `ST_Intersects` predicate to link facilities with their containing administrative boundaries.\n",
    "- **Nearest Neighbor Join:** We computed centroids for administrative areas and then used a cross join with window functions to find the nearest centroid for each facility.\n",
    "- **Optimization:** We improved join performance by repartitioning data based on geohash values.\n",
    "- **Visualization:** We created interactive maps using SedonaKepler and SedonaPyDeck to visualize spatial join and zonal statistics results.\n",
    "\n",
    "### Final Thoughts:\n",
    "This notebook provides a detailed, Pythonic approach to handling spatial joins and related spatial operations in Wherobots using Apache Sedona. By leveraging Python‚Äôs DataFrame API, we maintain clean and readable code that is easy to modify and extend. Happy spatial data processing! üòä\n",
    "\n",
    "For additional details and further learning:\n",
    "- Check out the [Wherobots Documentation](https://docs.wherobots.com) for advanced topics.\n",
    "- Visit the [Apache Sedona GitHub Repository](https://github.com/apache/sedona) for source code and examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
