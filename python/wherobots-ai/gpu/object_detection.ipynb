{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37fe0da",
   "metadata": {},
   "source": [
    "![](https://wherobots.com/wp-content/uploads/2023/12/Inline-Blue_Black_onWhite.png)\n",
    "</br>\n",
    "<div style=\"display: flex;justify-content: flex-end; align-items: center; max-width: 100%; margin: auto; gap: 90px;\">\n",
    "    <!-- Main Content Box -->\n",
    "    <div style=\"position: relative; display: flex; flex-direction: column; gap: 30px; \n",
    "                font-family: Arial, sans-serif; line-height: 1.6; max-width: 800px; \n",
    "                padding: 30px; color: #ffffff; background: #121212; \n",
    "                border-radius: 10px; box-shadow: 0px 0px 20px rgba(0, 255, 255, 0.0); \n",
    "                overflow: hidden;\">\n",
    "        <!-- Introductory Text -->\n",
    "        <div style=\"position: relative; z-index: 2;\">\n",
    "               <h2 style=\"color: #00f5d4;\">WherobotsAI Raster Inference - Object Detection</h2>\n",
    "            <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "                This example demonstrates an object detection model \n",
    "                with <strong>Raster Inference</strong> to identify <span style=\"color: #00f5d4; font-weight: bold;\">\n",
    "                marine infrastructure</span> (offshore wind farms and platforms) in satellite imagery.\n",
    "            </p>\n",
    "            <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "                We will use a <strong>machine-learning model</strong> from <span style=\"color: #ff007f; font-weight: bold;\">\n",
    "                Satlas</span>, which was trained using imagery from the \n",
    "                <strong>European Space Agencyâ€™s Sentinel-2 satellites</strong>.\n",
    "            </p>\n",
    "        </div>\n",
    "    </div>\n",
    "    <!-- Right Section: Icons -->\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: flex-end; gap: 20px\">\n",
    "        <img src=\"assets/offshore_oil.png\" \n",
    "             alt=\"Setup Icon\" \n",
    "             style=\"width: 100%; height: 100%; border-radius: 8px;margin: 20px\">\n",
    "        <img src=\"assets/wind_farm.png\" \n",
    "             alt=\"Wind Engine Offshore\" \n",
    "             style=\"width: 100%; height: 100%; border-radius: 8px;margin: 20px \">\n",
    "    </div>\n",
    "\n",
    "</div>\n",
    "\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757e8aa",
   "metadata": {},
   "source": [
    "</br>\n",
    "<div style=\"position: relative; display: flex; flex-direction: column; gap: 20px; \n",
    "            font-family: Arial, sans-serif; line-height: 1.6; max-width: 90%; \n",
    "            margin: auto; padding: 30px; color: #ffffff; background: #121212; \n",
    "            border-radius: 10px;); \n",
    "            overflow: hidden;\">\n",
    "    <!-- Title Section -->\n",
    "    <div style=\"position: relative; z-index: 2; text-align: left;\">\n",
    "        <h2 style=\"color: #00f5d4;\">Set Up The WherobotsDB Context</h2>\n",
    "    </div>\n",
    "    <!-- Main Content -->\n",
    "    <div style=\"position: relative; z-index: 2;\">\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            Here we configure WherobotsDB to enable access to the necessary cloud object storage buckets with sample data.\n",
    "        </p>\n",
    "    </div>\n",
    "    <!-- Right Section: AI Icon -->\n",
    "    <div style=\"display: flex; justify-content: flex-end; position: relative; z-index: 2; margin-top: 10px;\">\n",
    "    </div>\n",
    "</div>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sedona.spark import SedonaContext\n",
    "from pyspark.sql.functions import expr, size, col\n",
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "from sedona.raster_utils.SedonaUtils import SedonaUtils\n",
    "import json\n",
    "\n",
    "config = SedonaContext.builder().appName('object-detection-batch-inference')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654ce00-87ec-4200-88ac-feac99575490",
   "metadata": {},
   "source": [
    "</br>\n",
    "<div style=\"position: relative; display: flex; flex-direction: column; gap: 20px; \n",
    "            font-family: Arial, sans-serif; line-height: 1.6; max-width: 90%; \n",
    "            margin: auto; padding: 30px; color: #ffffff; background: #121212; \n",
    "            border-radius: 10px;); \n",
    "            overflow: hidden;\">\n",
    "    <!-- Title Section -->\n",
    "    <div style=\"position: relative; z-index: 2; text-align: left;\">\n",
    "        <h2 style=\"color: #00f5d4;\">Load Satellite Imagery Efficiently</h2>\n",
    "    </div>\n",
    "    <!-- Main Content -->\n",
    "    <div style=\"position: relative; z-index: 2;\">\n",
    "<p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            In this step, we load the satellite imagery to run <strong style=\"color: #00f5d4;\">inference</strong> over.  \n",
    "            These <strong>GeoTIFF images</strong> are ingested as <strong style=\"color: #00f5d4;\">out-of-database or \"out-db\" rasters</strong> in \n",
    "            <strong>WherobotsDB</strong> and stored in the Spatial Catalog for easy access. Building out DB ensuring efficient storage and retrieval. You can learn more about his process here.\n",
    "        </p>\n",
    "    </div>\n",
    "    <!-- Right Section: AI Icon -->\n",
    "    <div style=\"display: flex; justify-content: flex-end; position: relative; z-index: 2; margin-top: 10px;\">\n",
    "    </div>\n",
    "</div>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a12ce3-e74c-4f34-bd5a-aa59891c7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raster_input = sedona.table(f\"wherobots_pro_data.satlas.offshore_satlas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab52fa-e311-4fc0-adc5-d76fb36c6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raster_input.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927cecb9-d564-4a4f-8962-19731417d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raster_input.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf51b66-1ec0-4831-b01d-6febb5053dde",
   "metadata": {},
   "source": [
    "</br>\n",
    "<div style=\"position: relative; display: flex; flex-direction: column; gap: 20px; \n",
    "            font-family: Arial, sans-serif; line-height: 1.6; max-width: 90%; \n",
    "            margin: auto; padding: 30px; color: #ffffff; background: #121212; \n",
    "            border-radius: 10px;); \n",
    "            overflow: hidden;\">\n",
    "    <!-- Title Section -->\n",
    "    <div style=\"position: relative; z-index: 2; text-align: left;\">\n",
    "        <h2 style=\"color: #00f5d4;\">Focus on a Coastal Region</h2>\n",
    "    </div>\n",
    "    <!-- Main Content -->\n",
    "    <div style=\"position: relative; z-index: 2;\">\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            With <strong>176,000 images</strong> covering most of Earth's coastlines, let's choose an area to focus on.\n",
    "        </p>\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            Draw a <span style=\"color: #00f5d4; font-weight: bold;\">polygon</span> around the <strong>Yellow Sea</strong> \n",
    "            off the east coast of China to define an area of interest (AOI).\n",
    "        </p>\n",
    "    </div>\n",
    "    <!-- Right Section: AI Icon -->\n",
    "    <div style=\"display: flex; justify-content: flex-end; position: relative; z-index: 2; margin-top: 10px;\">\n",
    "    </div>\n",
    "</div>\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8f026-ddbd-46ee-a92f-071de9371691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from leafmap import Map\n",
    "\n",
    "my_map = Map()\n",
    "my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9852a-abdf-4c32-92ac-86e9acf50c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_map.user_roi # this shows the last draw feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54154ce-2035-4799-85a1-8fc0b6e8447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_json = json.dumps(my_map.user_roi) # formats the python dictionary as a string so we can pass it to SQL\n",
    "df_raster_sub = df_raster_input.where(\n",
    "    expr(f\"\"\"ST_INTERSECTS(footprint, ST_GeomFromGeoJSON('{feature_json}'))\"\"\")\n",
    ")\n",
    "\n",
    "df_raster_sub.cache()\n",
    "print(f\"IMAGE COUNT: {df_raster_sub.count()}\")\n",
    "df_raster_sub.show(3, truncate=True)\n",
    "df_raster_sub.createOrReplaceTempView(\"df_raster_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a7426-5d5c-44b4-9c27-0778163ff657",
   "metadata": {},
   "source": [
    "</br>\n",
    "<div style=\"position: relative; display: flex; flex-direction: column; gap: 20px; \n",
    "            font-family: Arial, sans-serif; line-height: 1.6; max-width: 90%; \n",
    "            margin: auto; padding: 30px; color: #ffffff; background: #121212; \n",
    "            border-radius: 10px; \n",
    "            overflow: hidden;\">\n",
    "    <!-- Main Content -->\n",
    "    <div style=\"position: relative; z-index: 2;text-align: left;\">\n",
    "        <h2 style=\"color: #00f5d4;text-align: left;\">Viewing Results</h2>\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "           With our AOI defined we can see the footprints of the images in the area with the <code>SedonaKepler.create_map()</code> integration .\n",
    "        </p>\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "           Using <code>SedonaUtils.display_image()</code> we can view the images as well.\n",
    "        </p>\n",
    "    </div>\n",
    "    </br>\n",
    "    <!-- Right Section: Map Icon -->\n",
    "    <div style=\"display: flex; justify-content: flex-end; position: relative; z-index: 2; margin-top: 10px;\">\n",
    "\n",
    "</div>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c73c8-ff49-4b5d-9b7d-f9bbe9ad83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "\n",
    "map = SedonaKepler.create_map()\n",
    "\n",
    "SedonaKepler.add_df(map, df=df_raster_sub, name=\"Image Footprints\")\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc5abd-4229-404e-97a0-a9693bd42712",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "htmlDf = sedona.sql(f\"\"\"SELECT RS_AsImage(outdb_raster, 250), name as FROM df_raster_input limit 10\"\"\")\n",
    "SedonaUtils.display_image(htmlDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e55013-053f-4de6-b88f-1ca0b31a0ada",
   "metadata": {},
   "source": [
    "</br>\n",
    "<div style=\"position: relative; display: flex; flex-direction: column; gap: 20px; \n",
    "            font-family: Arial, sans-serif; line-height: 1.6; max-width: 90%; \n",
    "            margin: auto; padding: 30px; color: #ffffff; background: #121212; \n",
    "            border-radius: 10px;); \n",
    "            overflow: hidden;\">\n",
    "    <!-- Title Section -->\n",
    "    <div style=\"position: relative; z-index: 2; text-align: left;\">\n",
    "        <h2 style=\"color: #00f5d4;\">Run Predictions And Visualize Results</h2>\n",
    "    </div>\n",
    "    <!-- Main Content -->\n",
    "    <div style=\"position: relative; z-index: 2;\">\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            To run predictions, we will specify the model we wish to use. Some models are pre-loaded and made available in \n",
    "            <strong>Wherobots Cloud</strong>. We can also load our own models. \n",
    "        </p>\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            Inference can be run using <strong>Wherobots' Spatial SQL functions</strong>, in this case: <code>RS_DETECT_BBOXES()</code>\n",
    "        </p>\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            Here we generate predictions for the all images in the AOI.\n",
    "        </p>\n",
    "    </div>\n",
    "    <!-- Right Section: AI Icon -->\n",
    "    <div style=\"display: flex; justify-content: flex-end; position: relative; z-index: 2; margin-top: 10px;\">\n",
    "    </div>\n",
    "</div>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f647116-0022-4234-b5ef-64c09fcf20f7",
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-21T19:45:23.352Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'marine-satlas-sentinel2'\n",
    "\n",
    "predictions_df = sedona.sql(f\"\"\"\n",
    "SELECT\n",
    "  outdb_raster,\n",
    "  name as image_name,\n",
    "  detect_result.*\n",
    "FROM (\n",
    "  SELECT\n",
    "    outdb_raster,\n",
    "    name,\n",
    "    RS_DETECT_BBOXES('{model_id}', outdb_raster) AS detect_result\n",
    "  FROM\n",
    "    df_raster_input\n",
    ") AS detect_fields\n",
    "\"\"\")\n",
    "\n",
    "predictions_df.cache().count()\n",
    "predictions_df.filter(size(col(\"labels\")) == 0).show(3)\n",
    "predictions_df.where('image_name = \"449623202-8-8.tiff\"').show()\n",
    "predictions_df.createOrReplaceTempView(\"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666348a-ca17-47a5-a4f8-c94068f49c9c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "</br>\n",
    "<div style=\"position: relative; display: flex; flex-direction: column; gap: 20px; \n",
    "            font-family: Arial, sans-serif; line-height: 1.6; max-width: 90%; \n",
    "            margin: auto; padding: 30px; color: #ffffff; background: #121212; \n",
    "            border-radius: 10px;); \n",
    "            overflow: hidden;\">\n",
    "    <!-- Title Section -->\n",
    "    <div style=\"position: relative; z-index: 2; text-align: left;\">\n",
    "        <h2 style=\"color: #00f5d4;\">Run Predictions And Visualize Results</h2>\n",
    "    </div>\n",
    "    <!-- Main Content -->\n",
    "    <div style=\"position: relative; z-index: 2;\">\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            Since we ran inference across many country coastlines all over the world, many scenes don't contain wind farms and don't have positive detections. Now that we've generated predictions using our model over our satellite imagery, we can filter the geometries by confidence score with <code>RS_FILTER_BOX_CONFIDENCE</code> and by the integer label representing offshore wind farms, <code>1</code>, to locate predicted offshore wind farms.\n",
    "        </p>\n",
    "    </div>\n",
    "    <!-- Right Section: AI Icon -->\n",
    "    <div style=\"display: flex; justify-content: flex-end; position: relative; z-index: 2; margin-top: 10px;\">\n",
    "    </div>\n",
    "</div>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e8c42-82a6-42aa-9418-c317094bfb0a",
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-21T19:45:23.352Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_predictions = sedona.sql(f\"\"\"\n",
    "  SELECT\n",
    "    outdb_raster,\n",
    "    image_name,\n",
    "    filtered.*\n",
    "  FROM (\n",
    "    SELECT\n",
    "      outdb_raster,\n",
    "      image_name,\n",
    "      RS_FILTER_BOX_CONFIDENCE(bboxes_wkt, confidence_scores, labels, 0.65) AS filtered\n",
    "    FROM\n",
    "      predictions\n",
    "  ) AS temp\n",
    "    WHERE size(filtered.max_confidence_bboxes) > 0\n",
    "    AND array_contains(filtered.max_confidence_labels, '1')\n",
    "\"\"\")\n",
    "filtered_predictions.createOrReplaceTempView(\"filtered_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcfbb2-e762-4976-830d-9a63daccccde",
   "metadata": {},
   "source": [
    "\n",
    "</br>\n",
    "<div style=\"position: relative; display: flex; flex-direction: column; gap: 20px; \n",
    "            font-family: Arial, sans-serif; line-height: 1.6; max-width: 90%; \n",
    "            margin: auto; padding: 30px; color: #ffffff; background: #121212; \n",
    "            border-radius: 10px;); \n",
    "            overflow: hidden;\">\n",
    "    <!-- Title Section -->\n",
    "    <div style=\"position: relative; z-index: 2; text-align: left;\">\n",
    "        <h2 style=\"color: #00f5d4;\">Prepare Results</h2>\n",
    "    </div>\n",
    "    <!-- Main Content -->\n",
    "    <div style=\"position: relative; z-index: 2;\">\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "            Our final step before plotting our prediction results is to convert our table from a format where each row represents a raster scene's predictions to a format where each row represents one predicted bounding box. To do this, we combine our list columns with <code>arrays_zip</code> and then use <code>explode</code> to convert lists to rows. To convert our string column representing a geometry into a <code>GeometryType</code> column, we use <code>ST_GeomFromWKT</code> so we can plot it with <code>SedonaKepler</code>.\n",
    "        </p>\n",
    "    </div>\n",
    "    <!-- Right Section: AI Icon -->\n",
    "    <div style=\"display: flex; justify-content: flex-end; position: relative; z-index: 2; margin-top: 10px;\">\n",
    "    </div>\n",
    "</div>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105badd3-dd9e-4a2e-85ab-72bbfe6bdb44",
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-21T19:45:23.352Z"
    }
   },
   "outputs": [],
   "source": [
    "exploded_df = sedona.sql(\"\"\"\n",
    "SELECT\n",
    "    outdb_raster,\n",
    "    image_name,\n",
    "    exploded.*\n",
    "FROM (\n",
    "    SELECT\n",
    "        outdb_raster,\n",
    "        image_name,\n",
    "        explode(arrays_zip(max_confidence_bboxes, max_confidence_scores, max_confidence_labels)) AS exploded\n",
    "    FROM\n",
    "        filtered_predictions\n",
    ") temp\n",
    "\"\"\")\n",
    "df_exploded = exploded_df.withColumn(\"geometry\", expr(\"ST_GeomFromWkt(max_confidence_bboxes)\")).drop(\"max_confidence_bboxes\")\n",
    "print(df_exploded.cache().count())\n",
    "df_exploded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca987b-7bf7-40e8-98bb-7baee0171ac4",
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-21T19:45:23.353Z"
    }
   },
   "outputs": [],
   "source": [
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "\n",
    "map = SedonaKepler.create_map()\n",
    "\n",
    "SedonaKepler.add_df(map, df=df_exploded.drop(\"outdb_raster\"), name=\"Wind Farm Detections\")\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ff035-32bb-443b-9f0b-9f5bccbc06b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:12:45.920771Z",
     "iopub.status.busy": "2025-02-20T22:12:45.920378Z",
     "iopub.status.idle": "2025-02-20T22:12:45.923072Z",
     "shell.execute_reply": "2025-02-20T22:12:45.922628Z",
     "shell.execute_reply.started": "2025-02-20T22:12:45.920754Z"
    }
   },
   "source": [
    "\n",
    "</br>\n",
    "<div style=\"position: relative; display: flex; flex-direction: column; gap: 20px; \n",
    "            font-family: Arial, sans-serif; line-height: 1.6; max-width: 90%; \n",
    "            margin: auto; padding: 30px; color: #ffffff; background: #121212; \n",
    "            border-radius: 10px;); \n",
    "            overflow: hidden;\">\n",
    "    <!-- Title Section -->\n",
    "    <div style=\"position: relative; z-index: 2; text-align: left;\">\n",
    "        <h2 style=\"color: #00f5d4;\">Select a Footprint and Review the Image</h2>\n",
    "    </div>\n",
    "    <!-- Main Content -->\n",
    "    <div style=\"position: relative; z-index: 2;\">\n",
    "        <p style=\"font-size: 18px; color: #e0e0e0;\">\n",
    "        Select one of the detected <strong>footprints</strong> from the map above. \n",
    "        Copy the name of a detected bounding box and paste it into the query below \n",
    "        to retrieve the corresponding image.\n",
    "        </p>\n",
    "    </div>\n",
    "    <!-- Right Section: AI Icon -->\n",
    "    <div style=\"display: flex; justify-content: flex-end; position: relative; z-index: 2; margin-top: 10px;\">\n",
    "    </div>\n",
    "</div>\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67b12d-eeaf-4300-869c-35e94fc6d40e",
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-21T19:45:23.353Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "image_name = '2015411785-6-6.tiff'\n",
    "htmlDf = sedona.sql(f\"\"\"SELECT RS_AsImage(outdb_raster, 500), name as FROM df_raster_input WHERE name = '{image_name}' \"\"\")\n",
    "SedonaUtils.display_image(htmlDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952aaa1-9479-4bc5-98bc-461bc604bf48",
   "metadata": {},
   "source": [
    "### wherobots.inference Python API\n",
    "\n",
    "If you prefer python, wherobots.inference offers a module for registering the SQL inference functions as python functions. Below we run the same inference as before with `RS_DETECT_BBOXES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e631a91-6837-4bfe-a50f-6968eaac6933",
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-21T19:45:23.353Z"
    }
   },
   "outputs": [],
   "source": [
    "from wherobots.inference.engine.register import create_object_detection_udfs\n",
    "from pyspark.sql.functions import col\n",
    "rs_detect, rs_threshold_geoms =  create_object_detection_udfs(batch_size = 10, sedona=sedona)\n",
    "df = df_raster_input.withColumn(\"detect_result\", rs_detect(model_id, col(\"outdb_raster\"))).select(\n",
    "                               \"outdb_raster\",\n",
    "                               col(\"detect_result.bboxes_wkt\").alias(\"bboxes_wkt\"),\n",
    "                               col(\"detect_result.confidence_scores\").alias(\"confidence_scores\"),\n",
    "                               col(\"detect_result.labels\").alias(\"labels\")\n",
    "                           )\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a37e3-9b2d-4665-99a4-83a9b8c0ed1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
