{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37fe0da",
   "metadata": {},
   "source": [
    "![](https://wherobots.com/wp-content/uploads/2023/12/Inline-Blue_Black_onWhite@3x.png)\n",
    "\n",
    "## Wherobots Inference - Segmentation \n",
    "\n",
    "This example demonstrates query inference using a segmentation model with Wherobots Inference to identify solar farms in satellite imagery. We will use a machine-learning model from [Satlas](https://satlas.allen.ai/ai) <sup>1</sup> which was trained using imagery from the European Space Agencyâ€™s Sentinel-2 satellites.\n",
    "\n",
    "**Note: This notebook requires the Wherobots Inference functionality to be enabled and a GPU runtime selected in Wherobots Cloud. Please [contact us](https://wherobots.com/contact/) to enable these features.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fec939-6e1a-486a-93ec-d6ac7a7b9aaa",
   "metadata": {},
   "source": [
    "### Step 1: Set Up The WherobotsDB Context\n",
    "\n",
    "Here we configure WherobotsDB to enable access to the necessary cloud object storage buckets with sample data and to enable the WherobotsAI features in WherobotsDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from wherobots.inference.data.io import read_raster_table\n",
    "from sedona.spark import SedonaContext\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "config = SedonaContext.builder().appName('segmentation-batch-inference')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654ce00-87ec-4200-88ac-feac99575490",
   "metadata": {},
   "source": [
    "### 2: Load Satellite Imagery\n",
    "\n",
    "Next, we load the satellite imagery that we will be running inference over. These GeoTiff images are loaded as *out-db* rasters in WherobotsDB, where each row represents a different scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac10af4-5ccf-43bb-8aaf-947d01c3fb55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tif_folder_path = 's3a://wherobots-benchmark-prod/data/ml/satlas/'\n",
    "files_df = read_raster_table(tif_folder_path, sedona, limit=1000)\n",
    "df_raster_input = files_df.withColumn(\n",
    "        \"outdb_raster\", expr(\"RS_FromPath(path)\")\n",
    "    )\n",
    "\n",
    "df_raster_input.cache().show(truncate=False)\n",
    "\n",
    "df_raster_input.createOrReplaceTempView(\"df_raster_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e55013-053f-4de6-b88f-1ca0b31a0ada",
   "metadata": {},
   "source": [
    "### 3: Run Predictions And Visualize Results\n",
    "\n",
    "To run predictions we will specify the model we wish to use. Some models are pre-loaded and made available in Wherobots Cloud. We can also load our own models. Predictions can be run using Wherobot's Spatial SQL functions, in this case `RS_Segment`.\n",
    "\n",
    "Here we generate 100 predictions using `RS_Segment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4399933-2da4-4254-bfb3-aea354c3443f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = 'solar-satlas-sentinel2'\n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    " CREATE TEMP VIEW segment_fields AS (\n",
    "    SELECT\n",
    "    outdb_raster,\n",
    "    RS_SEGMENT('{model_id}', outdb_raster) AS segment_result\n",
    "  FROM\n",
    "    df_raster_input)\n",
    "\"\"\")\n",
    "\n",
    "predictions_df = sedona.sql(f\"\"\"\n",
    "SELECT\n",
    "  outdb_raster,\n",
    "  segment_result.*\n",
    "FROM segment_fields\n",
    "\"\"\")\n",
    "\n",
    "predictions_df.cache().show()\n",
    "\n",
    "predictions_df.createOrReplaceTempView(\"predictions_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a2bf5-ea20-400b-8b3a-cc3ea0b7ad88",
   "metadata": {},
   "source": [
    "Now that we've generated predictions using our model over our satellite imagery, we can use the `RS_Segment_To_Geoms` function to extract the geometries indicating the model has identified as possible solar farms. we'll specify the following:\n",
    "\n",
    "* a raster column to use for georeferencing our results\n",
    "* the prediction result from the previous step\n",
    "* our category label \"1\" returned by the model representing Solar Farms and the class map to use for assigning labels to the prediction\n",
    "* a confidence threshold between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad63ec-3f82-42de-835e-b16601de1405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_multipolys = sedona.sql(\"\"\"\n",
    "    WITH t AS (\n",
    "        SELECT RS_SEGMENT_TO_GEOMS(outdb_raster, confidence_array, array(1), class_map, 0.65) result\n",
    "        FROM predictions_df\n",
    "    )\n",
    "    SELECT result.* FROM t\n",
    "\"\"\")\n",
    "\n",
    "df_multipolys.cache().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a61163",
   "metadata": {},
   "source": [
    "Now we can save the multipolygon results out to Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71ba81-9686-43a4-bf16-2b40e56db77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "USER_S3_URL = os.environ.get(\"USER_S3_PATH\")\n",
    "output_path = USER_S3_URL + \"semantic_segmentation_multipoly_small100_results.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc593025-89cf-49ac-b061-50641e5796a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_multipolys.write.parquet(output_path, mode=\"overwrite\")\n",
    "\n",
    "df_multipolys = sedona.read.format(\"parquet\").load(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb843ad9-5241-4696-96bd-ce870a4a5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multipolys.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd554156",
   "metadata": {},
   "source": [
    "Since we ran inference across the state of Arizona, many scenes don't contain solar farms and don't have positive detections. Let's filter out scenes without detections so that we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4936d2-723b-4613-bf4e-d1fe3f1f8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multipolys.createOrReplaceTempView(\"df_multipolys\")\n",
    "\n",
    "df_collected = sedona.sql(\"\"\"\n",
    "    SELECT\n",
    "        class_name, average_pixel_confidence_score, ST_Collect(geometry) AS collected_geom\n",
    "    FROM\n",
    "        df_multipolys\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab528c-51e8-43ee-ba5f-981d50c20f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_multipolys = df_collected.filter(\"ST_IsEmpty(collected_geom) = False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78c5ab",
   "metadata": {},
   "source": [
    "This leaves us with a few predicted solar farm polygons for our 1000 satellite image samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76e228-a659-4980-9368-7515fedc3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multipolys.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8269f80",
   "metadata": {},
   "source": [
    "We'll plot these with SedonaKepler. Compare the satellite basemap with the predictions and see if there's a match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8690f-496f-4e36-91f5-0c67321e20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multipolys.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153615b-83e8-4a7b-8f21-efea59a93808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.maps.SedonaKepler import SedonaKepler\n",
    "config = {\n",
    "    'version': 'v1',\n",
    "    'config': {\n",
    "        'mapStyle': {\n",
    "            'styleType': 'light',\n",
    "            'topLayerGroups': {},\n",
    "            'visibleLayerGroups': {},\n",
    "            'mapStyles': {}\n",
    "        },\n",
    "    }\n",
    "}\n",
    "map = SedonaKepler.create_map(config=config)\n",
    "\n",
    "SedonaKepler.add_df(map, df=df_multipolys, name=\"Solar Farm Detections\")\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952aaa1-9479-4bc5-98bc-461bc604bf48",
   "metadata": {},
   "source": [
    "### wherobots.inference Python API\n",
    "\n",
    "If you prefer python, wherobots.inference offers a module for registering the SQL inference functions as python functions. Below we run the same inference as before with RS_SEGMENT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e631a91-6837-4bfe-a50f-6968eaac6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wherobots.inference.engine.register import create_semantic_segmentation_udfs\n",
    "from pyspark.sql.functions import col\n",
    "rs_segment =  create_semantic_segmentation_udfs(batch_size = 10, sedona=sedona)\n",
    "df = df_raster_input.withColumn(\"segment_result\", rs_segment(model_id, col(\"outdb_raster\"))).select(\n",
    "                               \"outdb_raster\",\n",
    "                               col(\"segment_result.confidence_array\").alias(\"confidence_array\"),\n",
    "                               col(\"segment_result.class_map\").alias(\"class_map\")\n",
    "                           )\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f379e56-6fdf-4825-9bb7-024781dea77d",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Bastani, Favyen, Wolters, Piper, Gupta, Ritwik, Ferdinando, Joe, and Kembhavi, Aniruddha. \"SatlasPretrain: A Large-Scale Dataset for Remote Sensing Image Understanding.\" *arXiv preprint arXiv:2211.15660* (2023). [https://doi.org/10.48550/arXiv.2211.15660](https://doi.org/10.48550/arXiv.2211.15660)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
